#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CSGOé¥°å“æŒ‡æ•°Kçº¿æ•°æ®åˆ†æç³»ç»Ÿ
ç»¼åˆè¿ç”¨é‡‘èå­¦ã€æ•°å­¦ã€ç»Ÿè®¡å­¦åˆ†æå¸‚åœºè§„å¾‹

æŒ‡æ•°è¯´æ˜ï¼š
- è®¡ç®—æ–¹æ³•ï¼šå„é¥°å“ä»·æ ¼å˜åŒ–ç‡çš„å¹³å‡å€¼
- æ ·æœ¬ï¼š11269ä»¶å¹³å°åœ¨å”®æ•°>50çš„é¥°å“
- æ¶ˆé™¤é‡çº²å½±å“ï¼šé‡‡ç”¨å»é‡çº²åŒ–å¤„ç†

åŠŸèƒ½æ¨¡å—ï¼š
1. æŠ€æœ¯åˆ†æ - å‡çº¿ã€MACDã€RSIã€å¸ƒæ—å¸¦ç­‰
2. ç»Ÿè®¡åˆ†æ - æ³¢åŠ¨ç‡ã€ååº¦ã€å³°åº¦ã€è‡ªç›¸å…³
3. è¶‹åŠ¿åˆ†æ - æ—¶é—´åºåˆ—ã€å‘¨æœŸæ€§ã€è½¬æŠ˜ç‚¹
4. é£é™©åˆ†æ - æœ€å¤§å›æ’¤ã€å¤æ™®æ¯”ç‡ã€é£é™©æ”¶ç›Šæ¯”
5. é¢„æµ‹åˆ†æ - ARIMAã€æŒ‡æ•°å¹³æ»‘ã€è¶‹åŠ¿å¤–æ¨
"""

import requests
import json
import numpy as np
import pandas as pd
from datetime import datetime, timedelta
import matplotlib.pyplot as plt
from scipy import stats
from scipy.signal import find_peaks
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LinearRegression
import warnings
import time
warnings.filterwarnings('ignore')

import pickle
import os
from pathlib import Path

# ============================================================================
# 0.5 æ¨¡å‹æŒä¹…åŒ–ç®¡ç†å™¨
# ============================================================================

class ModelPersistenceManager:
    """æ¨¡å‹æŒä¹…åŒ–ç®¡ç†å™¨ - æ”¯æŒæ¨¡å‹ä¿å­˜ã€åŠ è½½å’Œç‰ˆæœ¬ç®¡ç†"""
    
    def __init__(self, model_dir="/Users/user/Downloads/csgoAuto/models", index_id=3, kline_type="1hour"):
        self.model_dir = model_dir
        self.index_id = index_id
        self.kline_type = kline_type
        
        # åˆ›å»ºæ¨¡å‹ç›®å½•
        Path(self.model_dir).mkdir(parents=True, exist_ok=True)
        
        # æ¨¡å‹å­˜å‚¨è·¯å¾„
        self.model_prefix = f"{self.model_dir}/model_idx{index_id}_{kline_type}"
        
    def _get_model_path(self, model_name):
        """è·å–æ¨¡å‹æ–‡ä»¶è·¯å¾„"""
        return f"{self.model_prefix}_{model_name}.pkl"
    
    def _get_metadata_path(self):
        """è·å–å…ƒæ•°æ®æ–‡ä»¶è·¯å¾„"""
        return f"{self.model_prefix}_metadata.json"
    
    def _get_history_path(self):
        """è·å–è®­ç»ƒå†å²æ–‡ä»¶è·¯å¾„"""
        return f"{self.model_prefix}_history.json"
    
    def save_model(self, model, model_name):
        """ä¿å­˜æ¨¡å‹"""
        try:
            path = self._get_model_path(model_name)
            with open(path, 'wb') as f:
                pickle.dump(model, f)
            return True
        except Exception as e:
            print(f"âŒ ä¿å­˜æ¨¡å‹ {model_name} å¤±è´¥: {e}")
            return False
    
    def load_model(self, model_name):
        """åŠ è½½æ¨¡å‹"""
        try:
            path = self._get_model_path(model_name)
            if not os.path.exists(path):
                return None
            with open(path, 'rb') as f:
                model = pickle.load(f)
            return model
        except Exception as e:
            print(f"âŒ åŠ è½½æ¨¡å‹ {model_name} å¤±è´¥: {e}")
            return False
    
    def model_exists(self, model_name):
        """æ£€æŸ¥æ¨¡å‹æ˜¯å¦å­˜åœ¨"""
        return os.path.exists(self._get_model_path(model_name))
    
    def save_metadata(self, metadata):
        """ä¿å­˜å…ƒæ•°æ®ï¼ˆè®­ç»ƒæ—¶é—´ã€æ•°æ®èŒƒå›´ç­‰ï¼‰"""
        try:
            path = self._get_metadata_path()
            with open(path, 'w') as f:
                json.dump(metadata, f, indent=2, default=str)
            return True
        except Exception as e:
            print(f"âŒ ä¿å­˜å…ƒæ•°æ®å¤±è´¥: {e}")
            return False
    
    def load_metadata(self):
        """åŠ è½½å…ƒæ•°æ®"""
        try:
            path = self._get_metadata_path()
            if not os.path.exists(path):
                return None
            with open(path, 'r') as f:
                metadata = json.load(f)
            return metadata
        except Exception as e:
            print(f"âŒ åŠ è½½å…ƒæ•°æ®å¤±è´¥: {e}")
            return None
    
    def add_training_history(self, training_info):
        """æ·»åŠ è®­ç»ƒå†å²è®°å½•"""
        try:
            path = self._get_history_path()
            
            # åŠ è½½ç°æœ‰å†å²
            if os.path.exists(path):
                with open(path, 'r') as f:
                    history = json.load(f)
            else:
                history = []
            
            # æ·»åŠ æ–°è®°å½•
            history.append(training_info)
            
            # ä¿å­˜
            with open(path, 'w') as f:
                json.dump(history, f, indent=2, default=str)
            
            return True
        except Exception as e:
            print(f"âŒ ä¿å­˜è®­ç»ƒå†å²å¤±è´¥: {e}")
            return False
    
    def get_training_history(self):
        """è·å–è®­ç»ƒå†å²"""
        try:
            path = self._get_history_path()
            if not os.path.exists(path):
                return []
            with open(path, 'r') as f:
                history = json.load(f)
            return history
        except Exception as e:
            print(f"âŒ åŠ è½½è®­ç»ƒå†å²å¤±è´¥: {e}")
            return []
    
    def show_training_history(self):
        """æ˜¾ç¤ºè®­ç»ƒå†å²"""
        history = self.get_training_history()
        if not history:
            print("ğŸ“Š è¿˜æ²¡æœ‰è®­ç»ƒå†å²è®°å½•")
            return
        
        print("\nğŸ“š è®­ç»ƒå†å²è®°å½•:")
        print("=" * 80)
        for i, record in enumerate(history[-10:], 1):  # æ˜¾ç¤ºæœ€å10æ¡
            timestamp = record.get('timestamp', 'N/A')
            arima_rmse = record.get('arima_rmse', 'N/A')
            prophet_rmse = record.get('prophet_rmse', 'N/A')
            xgb_rmse = record.get('xgb_rmse', 'N/A')
            improvement = record.get('improvement_percent', 'N/A')
            
            print(f"\n  #{len(history) - 10 + i} - {timestamp}")
            print(f"     ARIMA RMSE:   {arima_rmse}")
            print(f"     Prophet RMSE: {prophet_rmse}")
            print(f"     XGBoost RMSE: {xgb_rmse}")
            if improvement != 'N/A' and isinstance(improvement, (int, float)):
                print(f"     ğŸ“ˆ ç›¸æ¯”ä¸Šæ¬¡æ”¹è¿›: {improvement:.2f}%")
        
        print("\n" + "=" * 80)


# ============================================================================
# 0. Kçº¿å‘¨æœŸé…ç½®ç³»ç»Ÿ
# ============================================================================

class KlineConfig:
    """Kçº¿å‘¨æœŸé…ç½® - æ ¹æ®Kçº¿ç±»å‹è‡ªåŠ¨è°ƒæ•´åˆ†æå‚æ•°"""
    
    CONFIG = {
        '1day': {
            'name': 'æ—¥çº¿',
            'periods_per_year': 365,  # å…¨å¹´365å¤©å¯äº¤æ˜“
            'ma_fast': 5,             # å¿«é€Ÿå‡çº¿
            'ma_mid': 10,             # ä¸­æœŸå‡çº¿
            'ma_slow': 20,            # æ…¢é€Ÿå‡çº¿
            'rsi_window': 14,         # RSIå‘¨æœŸ
            'macd_fast': 12,          # MACDå¿«é€ŸEMA
            'macd_slow': 26,          # MACDæ…¢é€ŸEMA
            'macd_signal': 9,         # MACDä¿¡å·çº¿
            'bb_window': 20,          # å¸ƒæ—å¸¦å‘¨æœŸ
            'atr_window': 14,         # ATRå‘¨æœŸ
            'forecast_periods': [1, 7, 14],  # é¢„æµ‹å‘¨æœŸï¼ˆå¤©æ•°ï¼‰
            'volatility_lookback': 10,  # æ³¢åŠ¨ç‡å›çœ‹æœŸæ•°
            'trend_lookback': 60,     # è¶‹åŠ¿å›çœ‹æœŸæ•°
        },
        '1hour': {
            'name': 'å°æ—¶çº¿',
            'periods_per_year': 365 * 24,  # å°æ—¶æ•°ï¼ˆå…¨å¹´äº¤æ˜“å°æ—¶ = 8760ï¼‰
            'ma_fast': 12,            # å¿«é€Ÿå‡çº¿ï¼ˆå¯¹åº”3å°æ—¶ï¼‰
            'ma_mid': 24,             # ä¸­æœŸå‡çº¿ï¼ˆå¯¹åº”1å¤©ï¼‰
            'ma_slow': 72,            # æ…¢é€Ÿå‡çº¿ï¼ˆå¯¹åº”3å¤©ï¼‰
            'rsi_window': 14,         # RSIå‘¨æœŸä¿æŒä¸å˜
            'macd_fast': 12,          # MACDå‚æ•°å¯ä¿æŒï¼Œä½†è·¨åº¦æ›´å¤§
            'macd_slow': 26,
            'macd_signal': 9,
            'bb_window': 20,          # å¸ƒæ—å¸¦å‘¨æœŸ
            'atr_window': 14,         # ATRå‘¨æœŸ
            'forecast_periods': [1, 24, 168],  # é¢„æµ‹å‘¨æœŸï¼ˆå°æ—¶æ•°ï¼š1ã€24ã€168å°æ—¶å³7å¤©ï¼‰
            'volatility_lookback': 24,  # è¿‘24å°æ—¶æ³¢åŠ¨ç‡
            'trend_lookback': 240,    # 10å¤©è¶‹åŠ¿
        },
        '4hour': {
            'name': '4å°æ—¶çº¿',
            'periods_per_year': 365 * 6,  # 4å°æ—¶çº¿æ•° = 2190
            'ma_fast': 6,             # å¿«é€Ÿå‡çº¿ï¼ˆå¯¹åº”1å¤©ï¼‰
            'ma_mid': 12,             # ä¸­æœŸå‡çº¿ï¼ˆå¯¹åº”2å¤©ï¼‰
            'ma_slow': 30,            # æ…¢é€Ÿå‡çº¿ï¼ˆå¯¹åº”5å¤©ï¼‰
            'rsi_window': 14,
            'macd_fast': 12,
            'macd_slow': 26,
            'macd_signal': 9,
            'bb_window': 20,
            'atr_window': 14,
            'forecast_periods': [1, 6, 42],  # é¢„æµ‹å‘¨æœŸï¼ˆå•ä½ï¼šæ ¹æ®Kçº¿æ•°ï¼‰
            'volatility_lookback': 6,
            'trend_lookback': 60,
        },
        '7day': {
            'name': 'å‘¨çº¿',
            'periods_per_year': 52,  # å¹´å‘¨æ•°
            'ma_fast': 4,
            'ma_mid': 8,
            'ma_slow': 13,
            'rsi_window': 14,
            'macd_fast': 12,
            'macd_slow': 26,
            'macd_signal': 9,
            'bb_window': 20,
            'atr_window': 14,
            'forecast_periods': [1, 4, 12],  # é¢„æµ‹å‘¨æœŸï¼ˆå‘¨æ•°ï¼‰
            'volatility_lookback': 4,
            'trend_lookback': 52,
        }
    }
    
    @staticmethod
    def get_config(kline_type='1day'):
        """è·å–Kçº¿ç±»å‹å¯¹åº”çš„é…ç½®"""
        return KlineConfig.CONFIG.get(kline_type, KlineConfig.CONFIG['1day'])
    
    @staticmethod
    def get_annual_periods(kline_type='1day'):
        """è·å–å¹´åŒ–å‘¨æœŸæ•°"""
        return KlineConfig.get_config(kline_type)['periods_per_year']

# ============================================================================
# 1. æ•°æ®è·å–æ¨¡å—
# ============================================================================

class KlineDataFetcher:
    """Kçº¿æ•°æ®è·å–å™¨"""
    
    def __init__(self, base_url="http://localhost:8080"):
        self.base_url = base_url
        self.session = requests.Session()
    
    def fetch_kline(self, index_id=3, kline_type="1hour", verbose=True, max_retries=5):
        """
        è·å–Kçº¿æ•°æ®
        
        Args:
            index_id: æŒ‡æ•°ID (é»˜è®¤3 = CSGOé¥°å“å¤§ç›˜æŒ‡æ•°)
            kline_type: Kçº¿ç±»å‹ (1day, 1hour, 4hour, 7day)
            verbose: æ˜¯å¦æ‰“å°æ—¥å¿—
            max_retries: æœ€å¤§é‡è¯•æ¬¡æ•°
        
        Returns:
            DataFrame: åŒ…å« open, close, high, low, timestamp çš„æ•°æ®æ¡†
        """
        url = f"{self.base_url}/api/v1/sub/kline"
        params = {"id": index_id, "type": kline_type}
        
        retry_count = 0
        base_wait_time = 1  # åˆå§‹ç­‰å¾…æ—¶é—´ï¼ˆç§’ï¼‰
        
        while retry_count < max_retries:
            try:
                if verbose and retry_count > 0:
                    print(f"ğŸ“¡ é‡è¯•ç¬¬ {retry_count}/{max_retries} æ¬¡...")
                elif verbose:
                    print(f"ğŸ“¡ æ­£åœ¨è·å–Kçº¿æ•°æ®: {url}")
                    print(f"   å‚æ•°: {params}")
                
                response = self.session.get(url, params=params, timeout=30)
                
                if verbose:
                    print(f"   HTTPçŠ¶æ€ç : {response.status_code}")
                    print(f"   å“åº”å¤´: {response.headers}")
                    print(f"   å“åº”ä½“é•¿åº¦: {len(response.text)} å­—ç¬¦")
                
                # æ£€æŸ¥æ˜¯å¦æ˜¯ 429 Too Many Requests
                if response.status_code == 429:
                    retry_count += 1
                    if retry_count >= max_retries:
                        print(f"âŒ è·å–æ•°æ®å¤±è´¥: è¾¾åˆ°æœ€å¤§é‡è¯•æ¬¡æ•° ({max_retries}), æœåŠ¡å™¨è¿”å› 429 Too Many Requests")
                        return None
                    
                    # æŒ‡æ•°é€€é¿ç­–ç•¥
                    wait_time = base_wait_time * (2 ** (retry_count - 1))
                    # æ·»åŠ éšæœºæŠ–åŠ¨ï¼Œé¿å…é›·é¸£ç¾Šç¾¤æ•ˆåº”
                    jitter = np.random.uniform(0, wait_time * 0.1)
                    actual_wait_time = wait_time + jitter
                    
                    print(f"âš ï¸  æœåŠ¡å™¨é™æµ (429)ï¼Œç­‰å¾… {actual_wait_time:.1f} ç§’åé‡è¯•...")
                    time.sleep(actual_wait_time)
                    continue
                
                response.raise_for_status()
                
                # æ£€æŸ¥å“åº”æ˜¯å¦ä¸ºç©º
                if not response.text or response.text.strip() == "":
                    print("âŒ è·å–æ•°æ®å¤±è´¥: æœåŠ¡å™¨è¿”å›ç©ºå“åº”")
                    return None
                
                data = response.json()
                
                if data.get("code") != 200:
                    print(f"âŒ APIé”™è¯¯: {data.get('msg')}")
                    return None
                
                # è§£æKçº¿æ•°æ®
                kline_data = data.get("data", [])
                if not kline_data:
                    print("âš ï¸  æ²¡æœ‰è·å–åˆ°Kçº¿æ•°æ®")
                    return None
                
                # è½¬æ¢ä¸ºDataFrame
                df = pd.DataFrame(kline_data)
                
                # å¤„ç†æ—¶é—´æˆ³ - å¯èƒ½æ˜¯å­—ç¬¦ä¸²æ ¼å¼çš„æ¯«ç§’æ—¶é—´æˆ³
                if 't' in df.columns:
                    df['timestamp'] = pd.to_datetime(pd.to_numeric(df['t'], errors='coerce'), unit='ms', utc=True)
                    # è½¬æ¢ä¸ºUTC+8æ—¶åŒº
                    df['timestamp'] = df['timestamp'].dt.tz_convert('Asia/Shanghai')
                elif 'timestamp' in df.columns:
                    df['timestamp'] = pd.to_datetime(pd.to_numeric(df['timestamp'], errors='coerce'), unit='s', utc=True)
                    # è½¬æ¢ä¸ºUTC+8æ—¶åŒº
                    df['timestamp'] = df['timestamp'].dt.tz_convert('Asia/Shanghai')
                else:
                    print("âŒ æ— æ³•æ‰¾åˆ°æ—¶é—´æˆ³åˆ—")
                    return None
                
                df = df.sort_values('timestamp').reset_index(drop=True)
                
                # è½¬æ¢ä»·æ ¼ä¸ºfloat - å¤„ç†å¯èƒ½çš„å­—ç¬¦ä¸²æ ¼å¼
                price_columns = {}
                if 'o' in df.columns:
                    price_columns['open'] = 'o'
                if 'c' in df.columns:
                    price_columns['close'] = 'c'
                if 'h' in df.columns:
                    price_columns['high'] = 'h'
                if 'l' in df.columns:
                    price_columns['low'] = 'l'
                
                for std_col, api_col in price_columns.items():
                    if api_col in df.columns:
                        df[std_col] = pd.to_numeric(df[api_col], errors='coerce')
                
                # å¤„ç†æˆäº¤é‡
                if 'v' in df.columns:
                    df['volume'] = pd.to_numeric(df['v'], errors='coerce')
                
                if verbose:
                    print(f"âœ… æˆåŠŸè·å– {len(df)} æ¡Kçº¿æ•°æ®")
                    print(f"   æ—¶é—´èŒƒå›´: {df['timestamp'].min()} è‡³ {df['timestamp'].max()}")
                    if 'close' in df.columns:
                        print(f"   ä»·æ ¼èŒƒå›´: {df['close'].min():.2f} - {df['close'].max():.2f}\n")
                
                return df
                
            except json.JSONDecodeError as e:
                print(f"âŒ JSONè§£æå¤±è´¥: {e}")
                if verbose:
                    print(f"   å“åº”å†…å®¹å‰500å­—ç¬¦: {response.text[:500] if hasattr(response, 'text') else 'N/A'}")
                return None
            except requests.exceptions.ConnectionError as e:
                print(f"âŒ è¿æ¥å¤±è´¥: {e}")
                print(f"   è¯·ç¡®ä¿æœåŠ¡è¿è¡Œåœ¨ {self.base_url}")
                return None
            except requests.exceptions.Timeout as e:
                print(f"âŒ è¯·æ±‚è¶…æ—¶: {e}")
                return None
            except Exception as e:
                print(f"âŒ è·å–æ•°æ®å¤±è´¥: {e}")
                if verbose and hasattr(response, 'text'):
                    print(f"   å“åº”å†…å®¹: {response.text[:500]}")
                return None


# ============================================================================
# 2. æŠ€æœ¯åˆ†ææ¨¡å—
# ============================================================================

class TechnicalAnalysis:
    """æŠ€æœ¯åˆ†æå·¥å…·ç±»"""
    
    @staticmethod
    def moving_average(data, window):
        """è®¡ç®—ç®€å•ç§»åŠ¨å¹³å‡çº¿ (SMA)"""
        return data.rolling(window=window).mean()
    
    @staticmethod
    def exponential_moving_average(data, window):
        """è®¡ç®—æŒ‡æ•°ç§»åŠ¨å¹³å‡çº¿ (EMA)"""
        return data.ewm(span=window, adjust=False).mean()
    
    @staticmethod
    def macd(data, fast=12, slow=26, signal=9):
        """
        è®¡ç®—MACDæŒ‡æ ‡
        MACD = EMA12 - EMA26
        Signal = EMA9(MACD)
        Histogram = MACD - Signal
        """
        ema_fast = data.ewm(span=fast, adjust=False).mean()
        ema_slow = data.ewm(span=slow, adjust=False).mean()
        macd_line = ema_fast - ema_slow
        signal_line = macd_line.ewm(span=signal, adjust=False).mean()
        histogram = macd_line - signal_line
        return macd_line, signal_line, histogram
    
    @staticmethod
    def rsi(data, window=14):
        """
        ç›¸å¯¹å¼ºå¼±æŒ‡æ ‡ (RSI)
        RSI = 100 * U / (U + D)
        å…¶ä¸­U = å¹³å‡ä¸Šå‡å¹…åº¦, D = å¹³å‡ä¸‹é™å¹…åº¦
        """
        delta = data.diff()
        gain = (delta.where(delta > 0, 0)).rolling(window=window).mean()
        loss = (-delta.where(delta < 0, 0)).rolling(window=window).mean()
        rs = gain / loss
        rsi = 100 - (100 / (1 + rs))
        return rsi
    
    @staticmethod
    def bollinger_bands(data, window=20, num_std=2):
        """
        å¸ƒæ—å¸¦ (Bollinger Bands)
        ä¸­çº¿ = SMA(20)
        ä¸Šçº¿ = ä¸­çº¿ + 2*æ ‡å‡†å·®
        ä¸‹çº¿ = ä¸­çº¿ - 2*æ ‡å‡†å·®
        """
        sma = data.rolling(window=window).mean()
        std = data.rolling(window=window).std()
        upper = sma + (std * num_std)
        lower = sma - (std * num_std)
        return upper, sma, lower
    
    @staticmethod
    def atr(high, low, close, window=14):
        """
        å¹³å‡çœŸå®æ³¢å¹… (Average True Range)
        è¡¡é‡å¸‚åœºæ³¢åŠ¨æ€§
        """
        tr1 = high - low
        tr2 = abs(high - close.shift())
        tr3 = abs(low - close.shift())
        tr = pd.concat([tr1, tr2, tr3], axis=1).max(axis=1)
        atr = tr.rolling(window=window).mean()
        return atr
    
    @staticmethod
    def stochastic_oscillator(high, low, close, window=14, smooth_k=3, smooth_d=3):
        """
        éšæœºæŒ‡æ ‡ (%Kå’Œ%D)
        """
        lowest_low = low.rolling(window=window).min()
        highest_high = high.rolling(window=window).max()
        k_percent = 100 * ((close - lowest_low) / (highest_high - lowest_low))
        k_percent_smooth = k_percent.rolling(window=smooth_k).mean()
        d_percent = k_percent_smooth.rolling(window=smooth_d).mean()
        return k_percent_smooth, d_percent


# ============================================================================
# 3. ç»Ÿè®¡åˆ†ææ¨¡å—
# ============================================================================

class StatisticalAnalysis:
    """ç»Ÿè®¡åˆ†æå·¥å…·ç±»"""
    
    @staticmethod
    def calculate_returns(prices):
        """è®¡ç®—æ”¶ç›Šç‡ (å¯¹æ•°æ”¶ç›Šç‡)"""
        returns = np.log(prices / prices.shift(1))
        return returns.dropna()
    
    @staticmethod
    def volatility(returns, periods=252):
        """
        è®¡ç®—å¹´åŒ–æ³¢åŠ¨ç‡
        å¹´åŒ–æ³¢åŠ¨ç‡ = æ—¥æ³¢åŠ¨ç‡ * sqrt(252)
        """
        daily_vol = returns.std()
        annualized_vol = daily_vol * np.sqrt(periods)
        return annualized_vol
    
    @staticmethod
    def skewness_kurtosis(returns):
        """
        è®¡ç®—ååº¦å’Œå³°åº¦
        ååº¦: åˆ†å¸ƒçš„éå¯¹ç§°æ€§ (è´Ÿå€¼è¡¨ç¤ºå·¦åï¼Œæ­£å€¼è¡¨ç¤ºå³å)
        å³°åº¦: åˆ†å¸ƒçš„å°¾éƒ¨åšåº¦ (é«˜å³°åº¦è¡¨ç¤ºå¼‚å¸¸é£é™©å¤§)
        """
        skew = stats.skew(returns)
        kurt = stats.kurtosis(returns)
        return skew, kurt
    
    @staticmethod
    def autocorrelation(returns, lags=20):
        """
        è‡ªç›¸å…³åˆ†æ
        æ£€æµ‹æ”¶ç›Šç‡åºåˆ—ä¸­çš„æ¨¡å¼å’Œè®°å¿†æ•ˆåº”
        """
        acf = pd.Series(returns).autocorr(lag=lags)
        return acf
    
    @staticmethod
    def draw_down(prices):
        """
        è®¡ç®—æœ€å¤§å›æ’¤
        æœ€å¤§å›æ’¤ = (æœ€ä½ä»· - å³°å€¼) / å³°å€¼
        """
        cummax = prices.cummax()
        drawdown = (prices - cummax) / cummax
        max_drawdown = drawdown.min()
        return drawdown, max_drawdown
    
    @staticmethod
    def sharpe_ratio(returns, risk_free_rate=0.03, periods=252):
        """
        è®¡ç®—å¤æ™®æ¯”ç‡
        Sharpe Ratio = (å¹´åŒ–æ”¶ç›Šç‡ - æ— é£é™©åˆ©ç‡) / å¹´åŒ–æ³¢åŠ¨ç‡
        """
        annual_return = returns.mean() * periods
        annual_vol = returns.std() * np.sqrt(periods)
        sharpe = (annual_return - risk_free_rate) / annual_vol if annual_vol != 0 else 0
        return sharpe
    
    @staticmethod
    def calmar_ratio(returns, prices, periods=252):
        """
        è®¡ç®—Calmaræ¯”ç‡
        Calmar = å¹´åŒ–æ”¶ç›Šç‡ / æœ€å¤§å›æ’¤ç»å¯¹å€¼
        """
        _, max_dd = StatisticalAnalysis.draw_down(prices)
        annual_return = returns.mean() * periods
        calmar = annual_return / abs(max_dd) if max_dd != 0 else 0
        return calmar


# ============================================================================
# 4. è¶‹åŠ¿åˆ†ææ¨¡å—
# ============================================================================

class TrendAnalysis:
    """è¶‹åŠ¿åˆ†æå·¥å…·ç±»"""
    
    @staticmethod
    def linear_regression_trend(prices):
        """
        çº¿æ€§å›å½’è¶‹åŠ¿åˆ†æ
        è®¡ç®—è¶‹åŠ¿æ–¹å‘ã€æ–œç‡å’ŒRÂ²æ‹Ÿåˆåº¦
        """
        X = np.arange(len(prices)).reshape(-1, 1)
        y = prices.values.reshape(-1, 1)
        
        model = LinearRegression()
        model.fit(X, y)
        
        slope = model.coef_[0][0]
        r_squared = model.score(X, y)
        trend_line = model.predict(X).flatten()
        
        return {
            'slope': slope,
            'r_squared': r_squared,
            'trend_line': trend_line,
            'direction': 'ä¸Šå‡' if slope > 0 else 'ä¸‹é™'
        }
    
    @staticmethod
    def find_peaks_and_valleys(prices, distance=10):
        """
        è¯†åˆ«å³°å€¼å’Œè°·å€¼
        ç”¨äºè¯†åˆ«å¸‚åœºçš„è½¬æŠ˜ç‚¹
        """
        # å½’ä¸€åŒ–ä»·æ ¼
        prices_normalized = (prices - prices.mean()) / prices.std()
        
        # æ‰¾å³°å€¼
        peaks, _ = find_peaks(prices_normalized.values, distance=distance)
        valleys, _ = find_peaks(-prices_normalized.values, distance=distance)
        
        return peaks, valleys
    
    @staticmethod
    def trend_strength(high, low, close, period=14):
        """
        è¶‹åŠ¿å¼ºåº¦æŒ‡æ ‡
        åŸºäºDMI (Direction Movement Index)
        """
        up_move = high.diff()
        down_move = -low.diff()
        
        # è®¡ç®—ä¸Šå‡åŠ¨èƒ½å’Œä¸‹é™åŠ¨èƒ½
        plus_dm = (up_move.where((up_move > down_move) & (up_move > 0), 0)).rolling(period).mean()
        minus_dm = (down_move.where((down_move > up_move) & (down_move > 0), 0)).rolling(period).mean()
        
        tr = TechnicalAnalysis.atr(high, low, close, period)
        
        di_plus = 100 * plus_dm / tr if not tr.isna().all() else 0
        di_minus = 100 * minus_dm / tr if not tr.isna().all() else 0
        
        return di_plus, di_minus
    
    @staticmethod
    def cycle_detection(prices, min_period=5, max_period=100):
        """
        å‘¨æœŸæ€§æ£€æµ‹
        ä½¿ç”¨è‡ªç›¸å…³å‡½æ•°æ£€æµ‹å¸‚åœºçš„å‘¨æœŸæ€§
        """
        acf_values = []
        for lag in range(1, min(max_period, len(prices))):
            acf = pd.Series(prices).autocorr(lag=lag)
            acf_values.append(acf)
        
        # æ‰¾æœ€å¤§è‡ªç›¸å…³
        acf_array = np.array(acf_values)
        significant_lags = np.where(np.abs(acf_array) > 0.3)[0] + 1
        
        return significant_lags


# ============================================================================
# 5. é¢„æµ‹åˆ†ææ¨¡å—
# ============================================================================

class PredictiveAnalysis:
    """é¢„æµ‹åˆ†æå·¥å…·ç±»"""
    
    @staticmethod
    def exponential_smoothing(data, alpha=0.3):
        """
        æŒ‡æ•°å¹³æ»‘é¢„æµ‹
        """
        result = [data[0]]
        for i in range(1, len(data)):
            result.append(alpha * data[i] + (1 - alpha) * result[-1])
        return np.array(result)
    
    @staticmethod
    def trend_extrapolation(prices, forecast_periods=10):
        """
        è¶‹åŠ¿å¤–æ¨é¢„æµ‹
        åŸºäºçº¿æ€§å›å½’çš„ç®€å•è¶‹åŠ¿é¢„æµ‹
        """
        trend_info = TrendAnalysis.linear_regression_trend(prices)
        slope = trend_info['slope']
        
        last_price = prices.iloc[-1]
        forecast = []
        for i in range(1, forecast_periods + 1):
            forecast_price = last_price + slope * i
            forecast.append(forecast_price)
        
        return np.array(forecast)
    
    @staticmethod
    def moving_average_convergence(prices, short_window=5, long_window=20):
        """
        å‡çº¿æ”¶æ•›/ä¹–ç¦»é¢„æµ‹
        åŸºäºçŸ­æœŸå’Œé•¿æœŸå‡çº¿çš„äº¤å‰
        """
        sma_short = prices.rolling(window=short_window).mean()
        sma_long = prices.rolling(window=long_window).mean()
        
        # è®¡ç®—ä¹–ç¦»ç‡
        divergence = (sma_short - sma_long) / sma_long * 100
        
        # é¢„æµ‹ä¸‹ä¸€ä¸ªæ–¹å‘
        last_divergence = divergence.iloc[-1]
        prev_divergence = divergence.iloc[-2] if len(divergence) > 1 else last_divergence
        
        if last_divergence > 0 and prev_divergence < last_divergence:
            signal = "çœ‹æ¶¨"
        elif last_divergence < 0 and prev_divergence > last_divergence:
            signal = "çœ‹è·Œ"
        else:
            signal = "æŒå¹³"
        
        return divergence, signal


# ============================================================================
# 5.5 é«˜çº§é¢„æµ‹æ¨¡å—ï¼ˆå¤šæ¨¡å‹é›†æˆï¼‰
# ============================================================================

class AdvancedPredictiveAnalysis:
    """
    é«˜çº§é¢„æµ‹åˆ†æ - ä½¿ç”¨å¤šç§æ¨¡å‹é›†æˆé¢„æµ‹
    åŒ…å«: ARIMAã€æŒ‡æ•°å¹³æ»‘ã€Prophetã€åŠ æƒåŠ¨é‡é¢„æµ‹
    """
    
    @staticmethod
    def arima_forecast(prices, forecast_periods=7, order=(1, 1, 1)):
        """
        ARIMAæ¨¡å‹é¢„æµ‹
        order: (p, d, q) å‚æ•°
        """
        try:
            from statsmodels.tsa.arima.model import ARIMA
            
            # ç¡®ä¿æ•°æ®æ˜¯æ•°å€¼å‹
            prices_clean = prices.dropna().values
            
            if len(prices_clean) < 10:
                return None
            
            model = ARIMA(prices_clean, order=order)
            fitted_model = model.fit()
            forecast_result = fitted_model.get_forecast(steps=forecast_periods)
            
            # å¤„ç† predicted_mean - å®ƒå¯èƒ½æ˜¯ Series æˆ– ndarray
            predicted_mean = forecast_result.predicted_mean
            if hasattr(predicted_mean, 'values'):
                forecast_values = predicted_mean.values
            else:
                forecast_values = np.asarray(predicted_mean)
            
            # å¤„ç†ç½®ä¿¡åŒºé—´
            conf_int = None
            try:
                conf_int_result = forecast_result.conf_int()
                if hasattr(conf_int_result, 'values'):
                    conf_int = conf_int_result.values
                else:
                    conf_int = np.asarray(conf_int_result)
            except:
                pass
            
            return {
                'forecast': forecast_values,
                'confidence_intervals': conf_int,
                'aic': fitted_model.aic,
                'model': 'ARIMA'
            }
        except Exception as e:
            print(f"âš ï¸  ARIMAé¢„æµ‹å¤±è´¥: {e}")
            return None
    
    @staticmethod
    def exponential_smoothing_advanced(prices, forecast_periods=7):
        """
        é«˜çº§æŒ‡æ•°å¹³æ»‘é¢„æµ‹ (Holt-Winters)
        """
        try:
            from statsmodels.tsa.holtwinters import ExponentialSmoothing
            
            prices_clean = prices.dropna().values
            
            if len(prices_clean) < 10:
                return None
            
            # ä½¿ç”¨Holt-Winterså¹³æ»‘ï¼ˆadditiveæ¨¡å‹ï¼‰
            model = ExponentialSmoothing(
                prices_clean,
                trend='add',
                seasonal=None,
                initialization_method='estimated'
            )
            fitted_model = model.fit(optimized=True)
            forecast_values = fitted_model.forecast(steps=forecast_periods)
            
            return {
                'forecast': forecast_values,
                'model': 'Exponential Smoothing'
            }
        except Exception as e:
            print(f"âš ï¸  æŒ‡æ•°å¹³æ»‘é¢„æµ‹å¤±è´¥: {e}")
            return None
    
    @staticmethod
    def prophet_forecast(prices, timestamps, forecast_periods=7):
        """
        Facebook Prophetæ¨¡å‹é¢„æµ‹
        é€‚åˆå¤„ç†è¶‹åŠ¿å’Œå­£èŠ‚æ€§
        """
        try:
            from statsmodels.tsa.seasonal import seasonal_decompose
            
            prices_clean = prices.dropna()
            
            if len(prices_clean) < 20:
                return None
            
            # ç®€å•è¶‹åŠ¿ + åŠ¨é‡é¢„æµ‹
            # ä½¿ç”¨LOESSå¹³æ»‘ä¼°è®¡è¶‹åŠ¿
            trend_series = prices_clean.rolling(window=min(7, len(prices_clean)//3), center=True).mean()
            
            # è®¡ç®—æœ€è¿‘çš„è¶‹åŠ¿æ–œç‡
            recent_prices = prices_clean.iloc[-14:] if len(prices_clean) > 14 else prices_clean
            X = np.arange(len(recent_prices)).reshape(-1, 1)
            y = recent_prices.values
            
            model = LinearRegression()
            model.fit(X, y)
            recent_slope = model.coef_[0]
            
            # åŸºäºæœ€è¿‘è¶‹åŠ¿çš„é¢„æµ‹
            last_price = prices_clean.iloc[-1]
            forecast = []
            for i in range(1, forecast_periods + 1):
                # è¡°å‡å› å­ï¼Œè¿œæœŸé¢„æµ‹æ—¶è¶‹åŠ¿å½±å“é€æ¸å‡å¼±
                decay = 0.95 ** ((i - 1) / forecast_periods)
                pred = last_price + recent_slope * i * decay
                forecast.append(pred)
            
            return {
                'forecast': np.array(forecast),
                'trend_slope': recent_slope,
                'model': 'Prophet-Like'
            }
        except Exception as e:
            print(f"âš ï¸  Propheté¢„æµ‹å¤±è´¥: {e}")
            return None
    
    @staticmethod
    def weighted_momentum_forecast(prices, forecast_periods=7):
        """
        åŠ æƒåŠ¨é‡é¢„æµ‹ (æ”¹è¿›ç‰ˆ)
        ç»“åˆå¤šä¸ªæ—¶é—´å°ºåº¦çš„åŠ¨é‡ä¿¡æ¯ï¼Œå¹¶ä¼˜å…ˆè€ƒè™‘æœ€è¿‘è¶‹åŠ¿
        """
        try:
            prices_clean = prices.dropna()
            
            if len(prices_clean) < 10:
                return None
            
            last_price = prices_clean.iloc[-1]
            
            # è®¡ç®—ä¸åŒæ—¶é—´å°ºåº¦çš„åŠ¨é‡
            momenta = {}
            
            # 1æ—¥åŠ¨é‡
            if len(prices_clean) > 1:
                momenta['1d'] = (prices_clean.iloc[-1] - prices_clean.iloc[-2]) / prices_clean.iloc[-2]
            
            # 5æ—¥åŠ¨é‡
            if len(prices_clean) > 5:
                momenta['5d'] = (prices_clean.iloc[-1] - prices_clean.iloc[-5]) / prices_clean.iloc[-5]
            
            # 10æ—¥åŠ¨é‡
            if len(prices_clean) > 10:
                momenta['10d'] = (prices_clean.iloc[-1] - prices_clean.iloc[-10]) / prices_clean.iloc[-10]
            
            # 20æ—¥åŠ¨é‡
            if len(prices_clean) > 20:
                momenta['20d'] = (prices_clean.iloc[-1] - prices_clean.iloc[-20]) / prices_clean.iloc[-20]
            
            # æ£€æµ‹æœ€è¿‘çš„ä»·æ ¼è¶‹åŠ¿æ–¹å‘ï¼ˆæœ€é‡è¦ï¼‰
            recent_trend = None
            if len(prices_clean) > 5:
                recent_prices = prices_clean.iloc[-5:].values
                recent_trend = np.mean(np.diff(recent_prices))
            
            # æ”¹è¿›çš„æƒé‡åˆ†é…ï¼šä¼˜å…ˆè€ƒè™‘æœ€è¿‘è¶‹åŠ¿
            # å¦‚æœæœ€è¿‘æœ‰æ˜æ˜¾ä¸‹è·Œï¼Œå¢åŠ å…¶æƒé‡
            if recent_trend is not None and recent_trend < 0:
                # ä¸‹è·Œè¶‹åŠ¿ï¼šå¢åŠ æœ€è¿‘æœŸæƒé‡
                weights = {'1d': 0.5, '5d': 0.3, '10d': 0.15, '20d': 0.05}
            else:
                # å¹³å¸¸æƒé‡åˆ†é…
                weights = {'1d': 0.4, '5d': 0.3, '10d': 0.2, '20d': 0.1}
            
            weighted_momentum = sum(
                momenta.get(key, 0) * weights[key] 
                for key in weights.keys()
            ) / sum(v for k, v in weights.items() if k in momenta)
            
            # æ£€æµ‹å¼ºåŠ¿è¶‹åŠ¿ï¼ˆè¿ç»­3æ—¥ä¸‹è·Œæˆ–ä¸Šå‡ï¼‰
            if len(prices_clean) >= 3:
                last_3_returns = np.diff(prices_clean.iloc[-3:].values) / prices_clean.iloc[-3:-1].values
                all_negative = np.all(last_3_returns < 0)
                all_positive = np.all(last_3_returns > 0)
                
                if all_negative:
                    # è¿ç»­ä¸‹è·Œï¼šå¼ºåŒ–ä¸‹è·ŒåŠ¨é‡
                    weighted_momentum *= 1.3
                elif all_positive:
                    # è¿ç»­ä¸Šå‡ï¼šå¼ºåŒ–ä¸Šå‡åŠ¨é‡
                    weighted_momentum *= 1.2
            
            # åŸºäºåŠ æƒåŠ¨é‡è¿›è¡Œé¢„æµ‹
            forecast = []
            current_price = last_price
            
            for i in range(1, forecast_periods + 1):
                # æ”¹è¿›ï¼šåŠ¨é‡è¡°å‡æ›´é™¡å³­ï¼ˆé•¿æœŸé¢„æµ‹åº”è¯¥æ›´ä¿å®ˆï¼‰
                momentum_decay = weighted_momentum * (0.85 ** (i - 1))
                next_price = current_price * (1 + momentum_decay)
                forecast.append(next_price)
                current_price = next_price
            
            return {
                'forecast': np.array(forecast),
                'momentum': weighted_momentum,
                'momenta_detail': momenta,
                'recent_trend': recent_trend,
                'model': 'Weighted Momentum'
            }
        except Exception as e:
            print(f"âš ï¸  åŠ¨é‡é¢„æµ‹å¤±è´¥: {e}")
            return None
    
    @staticmethod
    def ensemble_forecast(prices, timestamps, forecast_periods=7):
        """
        é›†æˆé¢„æµ‹ - èåˆå¤šä¸ªæ¨¡å‹çš„é¢„æµ‹ç»“æœ
        ä½¿ç”¨å¹³å‡å€¼å’ŒåŠ æƒèåˆ
        """
        forecasts = {}
        
        # è·å–å„æ¨¡å‹é¢„æµ‹
        arima_result = AdvancedPredictiveAnalysis.arima_forecast(prices, forecast_periods)
        if arima_result:
            forecasts['ARIMA'] = {
                'values': arima_result['forecast'],
                'weight': 0.25,
                'aic': arima_result.get('aic', 0)
            }
        
        es_result = AdvancedPredictiveAnalysis.exponential_smoothing_advanced(prices, forecast_periods)
        if es_result:
            forecasts['ExponentialSmoothing'] = {
                'values': es_result['forecast'],
                'weight': 0.25
            }
        
        prophet_result = AdvancedPredictiveAnalysis.prophet_forecast(prices, timestamps, forecast_periods)
        if prophet_result:
            forecasts['Prophet'] = {
                'values': prophet_result['forecast'],
                'weight': 0.25
            }
        
        momentum_result = AdvancedPredictiveAnalysis.weighted_momentum_forecast(prices, forecast_periods)
        if momentum_result:
            forecasts['Momentum'] = {
                'values': momentum_result['forecast'],
                'weight': 0.25
            }
        
        # å¦‚æœæ²¡æœ‰ä»»ä½•æ¨¡å‹æˆåŠŸï¼Œè¿”å›None
        if not forecasts:
            return None
        
        # æ ‡å‡†åŒ–æƒé‡
        total_weight = sum(f['weight'] for f in forecasts.values())
        for model_name in forecasts:
            forecasts[model_name]['weight'] /= total_weight
        
        # è®¡ç®—åŠ æƒå¹³å‡é¢„æµ‹
        ensemble_forecast_values = np.zeros(forecast_periods)
        
        for model_name, model_data in forecasts.items():
            weighted_values = model_data['values'] * model_data['weight']
            ensemble_forecast_values += weighted_values
        
        # æ£€æµ‹å®é™…ä»·æ ¼è¶‹åŠ¿
        prices_clean = prices.dropna()
        if len(prices_clean) >= 5:
            # è®¡ç®—æœ€è¿‘5æ—¥çš„è¶‹åŠ¿
            recent_prices = prices_clean.iloc[-5:].values
            recent_returns = np.diff(recent_prices) / recent_prices[:-1]
            actual_trend = np.sum(recent_returns)  # æ€»å˜åŒ–ç‡
            
            # å¦‚æœå®é™…è¶‹åŠ¿æ˜æ˜¾å‘ä¸‹ï¼Œä½†é¢„æµ‹å‘ä¸Šï¼Œéœ€è¦è°ƒæ•´
            if actual_trend < -0.05 and ensemble_forecast_values[-1] > prices_clean.iloc[-1]:
                # å¼ºåŠ¿ä¸‹è·Œè¶‹åŠ¿ï¼Œè°ƒæ•´é¢„æµ‹æ›´ä¿å®ˆ
                current_price = prices_clean.iloc[-1]
                for i in range(len(ensemble_forecast_values)):
                    # å‰Šå¼±ä¸Šå‡é¢„æµ‹ï¼Œæˆ–è½¬å‘ä¸‹è·Œ
                    ensemble_forecast_values[i] = current_price * (1 + actual_trend * (0.5 + i/forecast_periods))
        
        return {
            'ensemble_forecast': ensemble_forecast_values,
            'individual_forecasts': {k: v['values'] for k, v in forecasts.items()},
            'model_weights': {k: v['weight'] for k, v in forecasts.items()},
            'models_used': len(forecasts)
        }
    
    @staticmethod
    def calculate_forecast_confidence(prices, forecast_values, forecast_periods):
        """
        è®¡ç®—é¢„æµ‹ç½®ä¿¡åº¦å’Œä¸ç¡®å®šæ€§åŒºé—´
        """
        returns = StatisticalAnalysis.calculate_returns(prices)
        volatility = StatisticalAnalysis.volatility(returns, periods=252)
        
        # è®¡ç®—ç½®ä¿¡åŒºé—´
        last_price = prices.iloc[-1]
        confidence_intervals = []
        
        for i in range(1, forecast_periods + 1):
            # åŸºäºå†å²æ³¢åŠ¨ç‡ä¼°è®¡æ ‡å‡†å·®
            std_error = last_price * volatility * np.sqrt(i)
            
            # 95%ç½®ä¿¡åŒºé—´
            upper_bound = forecast_values[i-1] + 1.96 * std_error
            lower_bound = forecast_values[i-1] - 1.96 * std_error
            
            confidence_intervals.append({
                'period': i,
                'forecast': forecast_values[i-1],
                'upper_95': upper_bound,
                'lower_95': lower_bound,
                'std_error': std_error
            })
        
        return confidence_intervals


# ============================================================================
# 6. ç»¼åˆåˆ†ææŠ¥å‘Šç”Ÿæˆå™¨
# ============================================================================

class AnalysisReporter:
    """ç»¼åˆåˆ†ææŠ¥å‘Šç”Ÿæˆå™¨"""
    
    @staticmethod
    def generate_report(df):
        """
        ç”Ÿæˆå…¨é¢çš„åˆ†ææŠ¥å‘Š
        """
        print("\n" + "="*80)
        print("                    CSGOé¥°å“å¤§ç›˜æŒ‡æ•°Kçº¿æ•°æ®åˆ†ææŠ¥å‘Š")
        print("="*80 + "\n")
        
        # åŸºç¡€ç»Ÿè®¡
        print("ã€ç¬¬ä¸€éƒ¨åˆ†ã€‘æŒ‡æ•°æ¦‚è§ˆä¸åŸºç¡€ç»Ÿè®¡")
        print("-" * 80)
        AnalysisReporter._basic_statistics(df)
        
        # æ”¶ç›Šç‡åˆ†æ
        print("\nã€ç¬¬äºŒéƒ¨åˆ†ã€‘æŒ‡æ•°å˜åŒ–ç‡ä¸é£é™©åˆ†æ")
        print("-" * 80)
        AnalysisReporter._return_analysis(df)
        
        # æŠ€æœ¯é¢åˆ†æ
        print("\nã€ç¬¬ä¸‰éƒ¨åˆ†ã€‘æŠ€æœ¯é¢åˆ†æ")
        print("-" * 80)
        AnalysisReporter._technical_analysis(df)
        
        # è¶‹åŠ¿åˆ†æ
        print("\nã€ç¬¬å››éƒ¨åˆ†ã€‘è¶‹åŠ¿ä¸å‘¨æœŸåˆ†æ")
        print("-" * 80)
        AnalysisReporter._trend_analysis(df)
        
        # é£é™©è¯„ä¼°
        print("\nã€ç¬¬äº”éƒ¨åˆ†ã€‘é£é™©è¯„ä¼°")
        print("-" * 80)
        AnalysisReporter._risk_assessment(df)
        
        # å¸‚åœºè§„å¾‹æ€»ç»“
        print("\nã€ç¬¬å…­éƒ¨åˆ†ã€‘å¤§ç›˜æŒ‡æ•°è§„å¾‹å‘ç°ä¸ç»“è®º")
        print("-" * 80)
        AnalysisReporter._market_patterns(df)
        
        # æŒ‡æ•°ä¿¡å·
        print("\nã€ç¬¬ä¸ƒéƒ¨åˆ†ã€‘æŒ‡æ•°æ–¹å‘ä¿¡å·")
        print("-" * 80)
        AnalysisReporter._trading_signals(df)
        
        # é¢„æµ‹æŠ¥å‘Š
        AnalysisReporter._generate_forecast_report(df)
        
        print("\n" + "="*80)
        print("                            æŠ¥å‘Šç”Ÿæˆå®Œæˆ")
        print("="*80 + "\n")
    
    @staticmethod
    def _basic_statistics(df):
        """åŸºç¡€ç»Ÿè®¡"""
        close_prices = df['close']
        
        print(f"ğŸ“Š æ•°æ®æ ·æœ¬é‡: {len(df)} æ¡")
        print(f"â° æ—¶é—´è·¨åº¦: {df['timestamp'].min().date()} è‡³ {df['timestamp'].max().date()}")
        print(f"ğŸ“ˆ å½“å‰æŒ‡æ•°: {close_prices.iloc[-1]:.2f}")
        print(f"ğŸ’° æœ€é«˜æŒ‡æ•°: {close_prices.max():.2f} (è·æœ€é«˜ç‚¹è·Œå¹…: {(1-close_prices.min()/close_prices.max())*100:.2f}%)")
        print(f"ğŸ’ æœ€ä½æŒ‡æ•°: {close_prices.min():.2f} (è·æœ€é«˜ç‚¹è·Œå¹…: {(1-close_prices.min()/close_prices.max())*100:.2f}%)")
        print(f"ğŸ“Š å¹³å‡æŒ‡æ•°: {close_prices.mean():.2f}")
        print(f"ğŸ“‰ æ³¢åŠ¨èŒƒå›´: {close_prices.max() - close_prices.min():.2f} ç‚¹")
        
        # ä¸åŒå‘¨æœŸçš„å˜åŒ–
        if len(df) >= 5:
            change_5 = (close_prices.iloc[-1] / close_prices.iloc[-5] - 1) * 100
            print(f"5æœŸæŒ‡æ•°æ¶¨è·Œ: {change_5:+.2f}%")
        if len(df) >= 10:
            change_10 = (close_prices.iloc[-1] / close_prices.iloc[-10] - 1) * 100
            print(f"10æœŸæŒ‡æ•°æ¶¨è·Œ: {change_10:+.2f}%")
        if len(df) >= 20:
            change_20 = (close_prices.iloc[-1] / close_prices.iloc[-20] - 1) * 100
            print(f"20æœŸæŒ‡æ•°æ¶¨è·Œ: {change_20:+.2f}%")
    
    @staticmethod
    def _return_analysis(df):
        """æ”¶ç›Šç‡åˆ†æ"""
        close_prices = df['close']
        returns = StatisticalAnalysis.calculate_returns(close_prices)
        
        print(f"ğŸ“ˆ æ—¥å‡æŒ‡æ•°å˜åŒ–ç‡: {returns.mean()*100:.4f}%")
        print(f"ğŸ“Š æ—¥æŒ‡æ•°å˜åŒ–æ ‡å‡†å·®: {returns.std()*100:.4f}%")
        print(f"ğŸ“‰ å¹´åŒ–æ³¢åŠ¨ç‡: {StatisticalAnalysis.volatility(returns)*100:.2f}%")
        
        skew, kurt = StatisticalAnalysis.skewness_kurtosis(returns)
        print(f"ğŸ”„ ååº¦ (Skewness): {skew:.4f}", end="")
        if skew < -0.5:
            print(" (å·¦å:æŒ‡æ•°æ˜“ä¸‹è·Œ)")
        elif skew > 0.5:
            print(" (å³å:æŒ‡æ•°æ˜“ä¸Šæ¶¨)")
        else:
            print(" (åŸºæœ¬å¯¹ç§°)")
        
        print(f"ğŸ“Œ å³°åº¦ (Kurtosis): {kurt:.4f}", end="")
        if kurt > 1:
            print(" (åšå°¾:æŒ‡æ•°å¼‚å¸¸æ³¢åŠ¨é¢‘ç¹)")
        else:
            print(" (æ­£å¸¸)")
        
        sharpe = StatisticalAnalysis.sharpe_ratio(returns)
        print(f"ğŸ“Š å¤æ™®æ¯”ç‡: {sharpe:.4f}", end="")
        if sharpe > 1:
            print(" (ä¼˜ç§€çš„æ”¶ç›Šé£é™©æ¯”)")
        elif sharpe > 0:
            print(" (ä¸€èˆ¬çš„æ”¶ç›Šé£é™©æ¯”)")
        else:
            print(" (äºæŸ)")
        
        drawdown, max_dd = StatisticalAnalysis.draw_down(close_prices)
        print(f"ğŸ“‰ æœ€å¤§å›æ’¤: {max_dd*100:.2f}% (ä»é«˜ç‚¹ä¸‹è·Œå¹…åº¦)")
    
    @staticmethod
    def _technical_analysis(df):
        """æŠ€æœ¯é¢åˆ†æ"""
        close = df['close']
        high = df['high']
        low = df['low']
        
        # MA
        ma5 = TechnicalAnalysis.moving_average(close, 5)
        ma10 = TechnicalAnalysis.moving_average(close, 10)
        ma20 = TechnicalAnalysis.moving_average(close, 20)
        
        print("æŒ‡æ•°å‡çº¿ç³»ç»Ÿ:")
        print(f"  MA5: {ma5.iloc[-1]:.2f}")
        print(f"  MA10: {ma10.iloc[-1]:.2f}")
        print(f"  MA20: {ma20.iloc[-1]:.2f}")
        print(f"  å½“å‰æŒ‡æ•°: {close.iloc[-1]:.2f}")
        
        # ä»·æ ¼ä¸å‡çº¿å…³ç³»
        if close.iloc[-1] > ma5.iloc[-1] > ma10.iloc[-1] > ma20.iloc[-1]:
            print("  â†’ å¤šå¤´æ’åˆ— ğŸ“ˆ (æŒ‡æ•°å¼ºåŠ¿)")
        elif close.iloc[-1] < ma5.iloc[-1] < ma10.iloc[-1] < ma20.iloc[-1]:
            print("  â†’ ç©ºå¤´æ’åˆ— ğŸ“‰ (æŒ‡æ•°å¼±åŠ¿)")
        else:
            print("  â†’ æ··åˆæ’åˆ— â†’ (è§‚æœ›)")
        
        # MACD
        macd_line, signal_line, histogram = TechnicalAnalysis.macd(close)
        print(f"\nMACDæŒ‡æ ‡:")
        print(f"  MACDçº¿: {macd_line.iloc[-1]:.4f}")
        print(f"  ä¿¡å·çº¿: {signal_line.iloc[-1]:.4f}")
        print(f"  æŸ±çŠ¶å›¾: {histogram.iloc[-1]:.4f}")
        if macd_line.iloc[-1] > signal_line.iloc[-1]:
            print("  â†’ é‡‘å‰ä¿¡å· (æŒ‡æ•°ä¸Šå‡åŠ¨åŠ›)")
        else:
            print("  â†’ æ­»å‰ä¿¡å· (æŒ‡æ•°ä¸‹é™åŠ¨åŠ›)")
        
        # RSI
        rsi = TechnicalAnalysis.rsi(close, 14)
        print(f"\nRSIæŒ‡æ ‡ (14): {rsi.iloc[-1]:.2f}")
        if rsi.iloc[-1] > 70:
            print("  â†’ è¶…ä¹°åŒºåŸŸ (æŒ‡æ•°å¯èƒ½è°ƒæ•´)")
        elif rsi.iloc[-1] < 30:
            print("  â†’ è¶…å–åŒºåŸŸ (æŒ‡æ•°å¯èƒ½åå¼¹)")
        else:
            print("  â†’ æ­£å¸¸åŒºåŸŸ")
        
        # å¸ƒæ—å¸¦
        upper, mid, lower = TechnicalAnalysis.bollinger_bands(close, 20, 2)
        print(f"\nå¸ƒæ—å¸¦:")
        print(f"  ä¸Šè½¨: {upper.iloc[-1]:.2f}")
        print(f"  ä¸­è½¨: {mid.iloc[-1]:.2f}")
        print(f"  ä¸‹è½¨: {lower.iloc[-1]:.2f}")
        print(f"  å½“å‰: {close.iloc[-1]:.2f}")
        if close.iloc[-1] > upper.iloc[-1]:
            print("  â†’ è§¦åŠä¸Šè½¨ (æŒ‡æ•°å¯èƒ½è§é¡¶)")
        elif close.iloc[-1] < lower.iloc[-1]:
            print("  â†’ è§¦åŠä¸‹è½¨ (æŒ‡æ•°å¯èƒ½è§åº•)")
        else:
            bb_pct = (close.iloc[-1] - lower.iloc[-1]) / (upper.iloc[-1] - lower.iloc[-1])
            print(f"  â†’ ä½ç½® {bb_pct*100:.1f}% (ä¸­æ€§åŒºåŸŸ)")
    
    @staticmethod
    def _trend_analysis(df):
        """è¶‹åŠ¿åˆ†æ"""
        close = df['close']
        high = df['high']
        low = df['low']
        
        # çº¿æ€§å›å½’
        trend_info = TrendAnalysis.linear_regression_trend(close)
        print(f"ğŸ“‰ çº¿æ€§è¶‹åŠ¿:")
        print(f"  æ–¹å‘: {trend_info['direction']}")
        print(f"  æ–œç‡: {trend_info['slope']:.6f} ç‚¹/å‘¨æœŸ")
        print(f"  æ‹Ÿåˆåº¦ (RÂ²): {trend_info['r_squared']:.4f}")
        
        # å³°å€¼è°·å€¼
        peaks, valleys = TrendAnalysis.find_peaks_and_valleys(close)
        print(f"\nğŸ”„ æŒ‡æ•°è½¬æŠ˜ç‚¹:")
        print(f"  å†å²å³°å€¼: {len(peaks)} ä¸ª", end="")
        if len(peaks) > 0:
            print(f" (æœ€è¿‘: ç¬¬{len(close)-peaks[-1]}æœŸå‰)")
        else:
            print()
        print(f"  å†å²è°·å€¼: {len(valleys)} ä¸ª", end="")
        if len(valleys) > 0:
            print(f" (æœ€è¿‘: ç¬¬{len(close)-valleys[-1]}æœŸå‰)")
        else:
            print()
        
        # è¶‹åŠ¿å¼ºåº¦
        di_plus, di_minus = TrendAnalysis.trend_strength(high, low, close, 14)
        print(f"\nğŸ’ª è¶‹åŠ¿å¼ºåº¦ (DMI):")
        print(f"  +DI: {di_plus.iloc[-1]:.2f}")
        print(f"  -DI: {di_minus.iloc[-1]:.2f}")
        if di_plus.iloc[-1] > di_minus.iloc[-1]:
            print("  â†’ ä¸Šå‡è¶‹åŠ¿å¼ºåŠ¿")
        else:
            print("  â†’ ä¸‹è·Œè¶‹åŠ¿å¼ºåŠ¿")
        
        # å‘¨æœŸæ€§
        cycles = TrendAnalysis.cycle_detection(close)
        if len(cycles) > 0:
            print(f"\nğŸ” å‘¨æœŸæ€§æ£€æµ‹:")
            print(f"  æ£€æµ‹åˆ°æ˜¾è‘—å‘¨æœŸ: {cycles.tolist()[:5]}")
        else:
            print(f"\nğŸ” å‘¨æœŸæ€§æ£€æµ‹: æœªæ£€æµ‹åˆ°æ˜¾è‘—å‘¨æœŸ")
    
    @staticmethod
    def _risk_assessment(df):
        """é£é™©è¯„ä¼°"""
        close = df['close']
        returns = StatisticalAnalysis.calculate_returns(close)
        
        # VaR (Value at Risk)
        var_95 = np.percentile(returns, 5)
        var_99 = np.percentile(returns, 1)
        
        print(f"ğŸ“Š é£é™©æŒ‡æ ‡:")
        print(f"  æ—¥ VaR (95%): {var_95*100:.4f}% (95%æ¦‚ç‡æ—¥æŸä¸è¶…è¿‡)")
        print(f"  æ—¥ VaR (99%): {var_99*100:.4f}% (99%æ¦‚ç‡æ—¥æŸä¸è¶…è¿‡)")
        
        # å‹åŠ›æµ‹è¯•
        worst_day = returns.min()
        best_day = returns.max()
        print(f"\n  æœ€å·®å•æ—¥: {worst_day*100:.2f}%")
        print(f"  æœ€å¥½å•æ—¥: {best_day*100:.2f}%")
        
        # é£é™©åˆ†çº§
        annual_vol = StatisticalAnalysis.volatility(returns)
        print(f"\nğŸ¯ é£é™©çº§åˆ«è¯„ä¼°:")
        print(f"  å¹´åŒ–æ³¢åŠ¨ç‡: {annual_vol*100:.2f}%")
        if annual_vol < 0.15:
            print("  è¯„çº§: ä½é£é™© âœ…")
        elif annual_vol < 0.30:
            print("  è¯„çº§: ä¸­ç­‰é£é™© âš ï¸")
        else:
            print("  è¯„çº§: é«˜é£é™© â›”")
    
    @staticmethod
    def _market_patterns(df):
        """å¸‚åœºè§„å¾‹å‘ç°"""
        close = df['close']
        returns = StatisticalAnalysis.calculate_returns(close)
        
        print("ğŸ” CSGOé¥°å“å¤§ç›˜æŒ‡æ•°è§„å¾‹å‘ç°:\n")
        
        # è§„å¾‹1ï¼šç›¸å¯¹åŸºå‡†ç‚¹çš„å˜åŒ– â†’ æ”¹ä¸ºç›¸å¯¹å½“å‰å¸‚åœºæ”¯æ’‘çš„å˜åŒ–
        print("1ï¸âƒ£  å¸‚åœºä¼°å€¼è§„å¾‹ (åŸºäºå½“å‰å¸‚åœºå®é™…æ”¯æ’‘):")
        current_index = close.iloc[-1]
        
        # è®¡ç®—æ›´æœ‰æ„ä¹‰çš„å¸‚åœºæŒ‡æ ‡
        median_price = close.median()  # å†å²ä¸­ä½æ•° - å¸‚åœºå¹³è¡¡ç‚¹
        ma_52week = close.iloc[-252:].mean() if len(close) > 252 else close.mean()  # 52å‘¨å‡çº¿
        recent_high = close.iloc[-60:].max()  # æœ€è¿‘60å¤©é«˜ç‚¹
        recent_low = close.iloc[-60:].min()   # æœ€è¿‘60å¤©ä½ç‚¹
        
        # ç›¸å¯¹ä¸­ä½æ•°çš„åç¦»ç¨‹åº¦
        median_deviation = (current_index / median_price - 1) * 100
        # ç›¸å¯¹52å‘¨å‡çº¿çš„åç¦»ç¨‹åº¦
        ma_deviation = (current_index / ma_52week - 1) * 100
        
        print(f"   å½“å‰æŒ‡æ•°: {current_index:.2f}")
        print(f"   å†å²ä¸­ä½æ•°: {median_price:.2f}")
        print(f"   ç›¸å¯¹ä¸­ä½æ•°åç¦»: {median_deviation:+.2f}%")
        print(f"   52å‘¨å‡çº¿: {ma_52week:.2f}")
        print(f"   ç›¸å¯¹52å‘¨å‡çº¿åç¦»: {ma_deviation:+.2f}%")
        print(f"   æœ€è¿‘60å¤©èŒƒå›´: {recent_low:.2f} - {recent_high:.2f}")
        
        # åŸºäºå½“å‰å¸‚åœºç»™å‡ºè¯„ä»·
        if current_index > recent_high * 0.95:
            print(f"   â†’ æŒ‡æ•°å¤„äºè¿‘æœŸé«˜ä½ï¼Œå­˜åœ¨è°ƒæ•´é£é™© âš ï¸")
        elif current_index < recent_low * 1.05:
            print(f"   â†’ æŒ‡æ•°å¤„äºè¿‘æœŸä½ä½ï¼Œå­˜åœ¨åå¼¹æœºä¼š ğŸ“ˆ")
        else:
            if median_deviation > 15:
                print(f"   â†’ æŒ‡æ•°ç›¸å¯¹å†å²å‡å€¼é«˜ä¼°ï¼Œéœ€å…³æ³¨é£é™© âš–ï¸")
            elif median_deviation < -15:
                print(f"   â†’ æŒ‡æ•°ç›¸å¯¹å†å²å‡å€¼ä½ä¼°ï¼Œå¯èƒ½å­˜åœ¨æœºä¼š ğŸ¯")
            else:
                print(f"   â†’ æŒ‡æ•°ç›¸å¯¹åˆç†ï¼Œå¸‚åœºå¤„äºå¹³è¡¡çŠ¶æ€ âš–ï¸")
        
        # è§„å¾‹2ï¼šåŠ¨é‡
        print("\n2ï¸âƒ£  æŒ‡æ•°åŠ¨é‡è§„å¾‹ (åæ˜ å¸‚åœºåŠ é€Ÿåº¦):")
        momentum_short = (close.iloc[-1] - close.iloc[-6]) / close.iloc[-6] * 100 if len(close) > 5 else 0
        momentum_long = (close.iloc[-1] - close.iloc[-21]) / close.iloc[-21] * 100 if len(close) > 20 else 0
        print(f"   5æœŸåŠ¨é‡: {momentum_short:+.2f}%")
        print(f"   20æœŸåŠ¨é‡: {momentum_long:+.2f}%")
        if momentum_short > 0 and momentum_long > 0:
            print("   â†’ åŒé‡ä¸Šå‡åŠ¨é‡ï¼Œé¥°å“æ•´ä½“å‡å€¼åŠ é€Ÿ ğŸš€")
        elif momentum_short < 0 and momentum_long < 0:
            print("   â†’ åŒé‡ä¸‹é™åŠ¨é‡ï¼Œé¥°å“æ•´ä½“è´¬å€¼åŠ é€Ÿ ğŸ”»")
        elif momentum_short > 0 and momentum_long < 0:
            print("   â†’ çŸ­æœŸåå¼¹ï¼Œä½†é•¿æœŸè¶‹åŠ¿ä»ä¸‹è¡Œ")
        else:
            print("   â†’ çŸ­æœŸéœ‡è¡ï¼Œé•¿æœŸè¶‹åŠ¿å‘ä¸Š")
        
        # è§„å¾‹3ï¼šæ³¢åŠ¨ç‡èšé›†
        print("\n3ï¸âƒ£  æ³¢åŠ¨ç‡èšé›†è§„å¾‹ (å¸‚åœºç¨³å®šæ€§):")
        vol_short = returns.iloc[-10:].std() if len(returns) > 10 else returns.std()
        vol_long = returns.std()
        vol_ratio = vol_short / vol_long if vol_long != 0 else 1
        print(f"   è¿‘æœŸæ³¢åŠ¨ç‡/å†å²å¹³å‡: {vol_ratio:.2f}")
        print(f"   å†å²æ—¥æ³¢åŠ¨ç‡: {vol_long*100:.4f}%")
        if vol_ratio > 1.5:
            print("   â†’ æ³¢åŠ¨ç‡å¤§å¹…ä¸Šå‡ï¼Œå¸‚åœºé£é™©å¢åŠ ï¼Œå®¹æ˜“å‡ºç°å¿«é€Ÿè¶‹åŠ¿ âš¡")
        elif vol_ratio < 0.7:
            print("   â†’ æ³¢åŠ¨ç‡å¤§å¹…ä¸‹é™ï¼Œå¸‚åœºé£é™©ä¸‹é™ï¼Œå¸‚åœºè¿›å…¥æ•´ç†é˜¶æ®µ â¸ï¸")
        else:
            print("   â†’ æ³¢åŠ¨ç‡ç›¸å¯¹ç¨³å®šï¼Œå¸‚åœºé£é™©å¤„äºæ­£å¸¸æ°´å¹³")
        
        # è§„å¾‹4ï¼šè‡ªç›¸å…³ä¸åè½¬
        print("\n4ï¸âƒ£  è‡ªç›¸å…³è§„å¾‹ (å¸‚åœºè®°å¿†æ•ˆåº”):")
        acf = pd.Series(returns).autocorr(lag=1)
        print(f"   1æœŸè‡ªç›¸å…³ç³»æ•°: {acf:.4f}")
        if acf > 0.1:
            print("   â†’ å­˜åœ¨æ­£ç›¸å…³ï¼ŒæŒ‡æ•°æœ‰æƒ¯æ€§ï¼Œä¸Šå‡/ä¸‹é™è¶‹åŠ¿å»¶ç»­å¯èƒ½æ€§å¤§")
        elif acf < -0.1:
            print("   â†’ å­˜åœ¨è´Ÿç›¸å…³ï¼ŒæŒ‡æ•°æ˜“åè½¬ï¼Œå¸‚åœºå…·æœ‰å‡å€¼å›å¤ç‰¹æ€§")
        else:
            print("   â†’ åŸºæœ¬ç‹¬ç«‹ï¼Œå¸‚åœºå‘ˆéšæœºæ¸¸èµ°ï¼Œæ— æ˜æ˜¾è§„å¾‹")
    
    @staticmethod
    def _trading_signals(df):
        """æŒ‡æ•°æ–¹å‘ä¿¡å·"""
        close = df['close']
        
        signals = []
        
        # ä¿¡å·1ï¼šå‡çº¿
        ma5 = TechnicalAnalysis.moving_average(close, 5)
        ma10 = TechnicalAnalysis.moving_average(close, 10)
        if close.iloc[-1] > ma5.iloc[-1] > ma10.iloc[-1]:
            signals.append(("å‡çº¿å¤šå¤´", "æŒ‡æ•°å¼ºåŠ¿â†‘", 70))
        elif close.iloc[-1] < ma5.iloc[-1] < ma10.iloc[-1]:
            signals.append(("å‡çº¿ç©ºå¤´", "æŒ‡æ•°å¼±åŠ¿â†“", 70))
        
        # ä¿¡å·2ï¼šMACD
        macd_line, signal_line, _ = TechnicalAnalysis.macd(close)
        if len(macd_line) > 1:
            if macd_line.iloc[-1] > signal_line.iloc[-1] and macd_line.iloc[-2] <= signal_line.iloc[-2]:
                signals.append(("MACDé‡‘å‰", "æŒ‡æ•°ä¸Šå‡åŠ¨åŠ›", 65))
            elif macd_line.iloc[-1] < signal_line.iloc[-1] and macd_line.iloc[-2] >= signal_line.iloc[-2]:
                signals.append(("MACDæ­»å‰", "æŒ‡æ•°ä¸‹é™åŠ¨åŠ›", 65))
        
        # ä¿¡å·3ï¼šRSI
        rsi = TechnicalAnalysis.rsi(close, 14)
        if rsi.iloc[-1] < 30:
            signals.append(("RSIè¶…å–", "æŒ‡æ•°è¿‡åº¦è°ƒæ•´", 60))
        elif rsi.iloc[-1] > 70:
            signals.append(("RSIè¶…ä¹°", "æŒ‡æ•°è¿‡åº¦ä¸Šå‡", 60))
        
        # ä¿¡å·4ï¼šå¸ƒæ—å¸¦
        upper, mid, lower = TechnicalAnalysis.bollinger_bands(close)
        if close.iloc[-1] < lower.iloc[-1]:
            signals.append(("å¸ƒæ—ä¸‹è½¨", "æŒ‡æ•°å¯èƒ½åå¼¹", 55))
        elif close.iloc[-1] > upper.iloc[-1]:
            signals.append(("å¸ƒæ—ä¸Šè½¨", "æŒ‡æ•°å¯èƒ½å›è°ƒ", 55))
        
        if not signals:
            print("ğŸ“Š å½“å‰ä¿¡å·: æ— æ˜ç¡®æ–¹å‘ä¿¡å· (æŒ‡æ•°å¤„äºè¿‡æ¸¡é˜¶æ®µï¼Œè§‚æœ›ä¸­)")
            return
        
        # èšåˆä¿¡å·
        up_signals = [s for s in signals if "â†‘" in s[1] or "ä¸Šå‡" in s[1] or "åå¼¹" in s[1]]
        down_signals = [s for s in signals if "â†“" in s[1] or "ä¸‹é™" in s[1] or "å›è°ƒ" in s[1]]
        
        avg_confidence = np.mean([s[2] for s in signals])
        
        if len(up_signals) > len(down_signals):
            print(f"ğŸŸ¢ ç»¼åˆæŒ‡æ•°ä¿¡å·: ä¸Šå‡è¶‹åŠ¿ (ç½®ä¿¡åº¦: {avg_confidence:.0f}%)")
        elif len(down_signals) > len(up_signals):
            print(f"ğŸ”´ ç»¼åˆæŒ‡æ•°ä¿¡å·: ä¸‹è·Œè¶‹åŠ¿ (ç½®ä¿¡åº¦: {avg_confidence:.0f}%)")
        else:
            print(f"ğŸŸ¡ ç»¼åˆæŒ‡æ•°ä¿¡å·: æ··åˆçŠ¶æ€ (ç½®ä¿¡åº¦: {avg_confidence:.0f}%)")
        
        print("\næŒ‡æ•°ä¿¡å·è¯¦è§£:")
        for signal_name, direction, confidence in sorted(signals, key=lambda x: -x[2]):
            emoji = "ğŸŸ¢" if "â†‘" in direction or "ä¸Šå‡" in direction or "åå¼¹" in direction else "ğŸ”´"
            print(f"  {emoji} {signal_name}: {direction} (ç½®ä¿¡åº¦: {confidence}%)")
    
    @staticmethod
    def _generate_forecast_report(df):
        """ç”Ÿæˆé¢„æµ‹åˆ†ææŠ¥å‘Š"""
        print("\nã€ç¬¬å…«éƒ¨åˆ†ã€‘æœªæ¥ä»·æ ¼é¢„æµ‹åˆ†æ")
        print("-" * 80)
        
        close = df['close']
        timestamp = df['timestamp']
        
        # 1å¤©ã€7å¤©ã€14å¤©é¢„æµ‹
        forecast_periods = [1, 7, 14]
        
        for periods in forecast_periods:
            print(f"\nğŸ“Š {periods}å¤©ä»·æ ¼é¢„æµ‹")
            print("=" * 60)
            
            # è·å–é›†æˆé¢„æµ‹
            ensemble_result = AdvancedPredictiveAnalysis.ensemble_forecast(
                close, timestamp, forecast_periods=periods
            )
            
            if ensemble_result is None:
                print(f"âŒ é¢„æµ‹å¤±è´¥: æ•°æ®ä¸è¶³")
                continue
            
            ensemble_forecast = ensemble_result['ensemble_forecast']
            individual_forecasts = ensemble_result['individual_forecasts']
            model_weights = ensemble_result['model_weights']
            
            # è®¡ç®—ç½®ä¿¡åŒºé—´
            confidence_intervals = AdvancedPredictiveAnalysis.calculate_forecast_confidence(
                close, ensemble_forecast, periods
            )
            
            current_price = close.iloc[-1]
            
            print(f"\nğŸ¯ é›†æˆé¢„æµ‹ç»“æœ (èåˆ {ensemble_result['models_used']} ä¸ªæ¨¡å‹):")
            print(f"   å½“å‰ä»·æ ¼: {current_price:.2f}")
            print(f"   {periods}å¤©ç›®æ ‡ä»·: {ensemble_forecast[-1]:.2f}")
            
            change_percent = (ensemble_forecast[-1] / current_price - 1) * 100
            emoji = "ğŸ“ˆ" if change_percent > 0 else "ğŸ“‰"
            print(f"   é¢„æœŸå˜åŒ–: {change_percent:+.2f}% {emoji}")
            
            # æ˜¾ç¤ºå„æ¨¡å‹æƒé‡å’Œé¢„æµ‹
            print(f"\nğŸ“‹ æ¨¡å‹è´¡çŒ®åº¦ä¸é¢„æµ‹:")
            for model_name in sorted(individual_forecasts.keys()):
                weight = model_weights[model_name] * 100
                forecast_value = individual_forecasts[model_name][-1]
                change = (forecast_value / current_price - 1) * 100
                print(f"   â€¢ {model_name:25s} | æƒé‡: {weight:5.1f}% | é¢„æµ‹: {forecast_value:8.2f} ({change:+6.2f}%)")
            
            # æ˜¾ç¤ºè¯¦ç»†é¢„æµ‹è·¯å¾„
            print(f"\nğŸ“ˆ é¢„æµ‹è·¯å¾„ (é€æ—¥é¢„æµ‹):")
            for conf_interval in confidence_intervals:
                period = int(conf_interval['period'])
                forecast = conf_interval['forecast']
                upper = conf_interval['upper_95']
                lower = conf_interval['lower_95']
                change = (forecast / current_price - 1) * 100
                
                print(f"   Day {period}: {forecast:8.2f} | 95%åŒºé—´: [{lower:8.2f}, {upper:8.2f}] | å˜åŒ–: {change:+6.2f}%")
            
            # é¢„æµ‹è¶‹åŠ¿åˆ†æ
            print(f"\nğŸ” é¢„æµ‹è¶‹åŠ¿åˆ†æ:")
            
            if ensemble_forecast[-1] > current_price * 1.05:
                print(f"   âœ… å¼ºçƒˆä¸Šå‡ä¿¡å· - é¢„æœŸæŒ‡æ•°å‘ä¸Šçªç ´")
            elif ensemble_forecast[-1] > current_price * 1.01:
                print(f"   ğŸ“ˆ æ¸©å’Œä¸Šå‡ä¿¡å· - é¢„æœŸæŒ‡æ•°ç¼“æ…¢ä¸Šå‡")
            elif ensemble_forecast[-1] < current_price * 0.95:
                print(f"   âš ï¸  å¼ºçƒˆä¸‹è·Œä¿¡å· - é¢„æœŸæŒ‡æ•°å‘ä¸‹è°ƒæ•´")
            elif ensemble_forecast[-1] < current_price * 0.99:
                print(f"   ğŸ“‰ æ¸©å’Œä¸‹è·Œä¿¡å· - é¢„æœŸæŒ‡æ•°ç¼“æ…¢ä¸‹è·Œ")
            else:
                print(f"   â¸ï¸  éœ‡è¡æ•´ç† - é¢„æœŸæŒ‡æ•°åœ¨å½“å‰ä½ç½®æ³¢åŠ¨")
            
            # æ˜¾ç¤ºæ³¢åŠ¨ç‡ä¿¡æ¯
            std_error_last = confidence_intervals[-1]['std_error']
            print(f"   ğŸ“Š é¢„æµ‹ä¸ç¡®å®šæ€§: Â±{std_error_last:.2f} (åŸºäºå†å²æ³¢åŠ¨ç‡ä¼°ç®—)")
            
            # æœ€å¤§ç›ˆåˆ©å’Œæœ€å¤§é£é™©
            max_forecast = max(cf['forecast'] for cf in confidence_intervals)
            min_forecast = min(cf['forecast'] for cf in confidence_intervals)
            max_profit = (max_forecast / current_price - 1) * 100
            max_loss = (min_forecast / current_price - 1) * 100
            
            print(f"   ğŸ’° æœ€å¤§ç›ˆåˆ©ç©ºé—´: +{max_profit:.2f}%")
            print(f"   âš ï¸  æœ€å¤§é£é™©ç©ºé—´: {max_loss:.2f}%")
            print(f"   ğŸ“Š é£é™©æ”¶ç›Šæ¯”: {abs(max_profit / max_loss) if max_loss != 0 else 'N/A':.2f}x")


# ============================================================================
# 7. å¯è§†åŒ–æ¨¡å—
# ============================================================================

def plot_analysis(df, output_file='kline_analysis.html'):
    """
    ç”Ÿæˆäº¤äº’å¼å¯è§†åŒ–å›¾è¡¨
    """
    try:
        import plotly.graph_objects as go
        from plotly.subplots import make_subplots
    except ImportError:
        print("âš ï¸  éœ€è¦å®‰è£… plotly: pip install plotly")
        return
    
    close = df['close']
    high = df['high']
    low = df['low']
    volume = df.get('volume', pd.Series(index=df.index, dtype=float))
    
    # åˆ›å»ºå­å›¾
    fig = make_subplots(
        rows=3, cols=1,
        shared_xaxes=True,
        row_heights=[0.5, 0.25, 0.25],
        subplot_titles=("æŒ‡æ•°Kçº¿å›¾", "æˆäº¤é‡", "MACD")
    )
    
    # Kçº¿å›¾
    fig.add_trace(
        go.Candlestick(
            x=df['timestamp'],
            open=df['open'],
            high=high,
            low=low,
            close=close,
            name='æŒ‡æ•°'
        ),
        row=1, col=1
    )
    
    # å‡çº¿
    ma5 = TechnicalAnalysis.moving_average(close, 5)
    ma10 = TechnicalAnalysis.moving_average(close, 10)
    ma20 = TechnicalAnalysis.moving_average(close, 20)
    
    fig.add_trace(go.Scatter(x=df['timestamp'], y=ma5, name='MA5', line=dict(color='orange')), row=1, col=1)
    fig.add_trace(go.Scatter(x=df['timestamp'], y=ma10, name='MA10', line=dict(color='blue')), row=1, col=1)
    fig.add_trace(go.Scatter(x=df['timestamp'], y=ma20, name='MA20', line=dict(color='red')), row=1, col=1)
    
    # æˆäº¤é‡
    if not volume.isna().all():
        fig.add_trace(
            go.Bar(x=df['timestamp'], y=volume, name='æˆäº¤é‡', marker_color='rgba(128,128,128,0.5)'),
            row=2, col=1
        )
    
    # MACD
    macd_line, signal_line, histogram = TechnicalAnalysis.macd(close)
    fig.add_trace(go.Scatter(x=df['timestamp'], y=macd_line, name='MACD', line=dict(color='blue')), row=3, col=1)
    fig.add_trace(go.Scatter(x=df['timestamp'], y=signal_line, name='Signal', line=dict(color='red')), row=3, col=1)
    
    fig.update_layout(height=1000, title_text="CSGOé¥°å“å¤§ç›˜æŒ‡æ•°Kçº¿åˆ†æå›¾", hovermode='x unified')
    fig.write_html(output_file)
    print(f"\nğŸ“Š å›¾è¡¨å·²ç”Ÿæˆ: {output_file}")


# ============================================================================
# 8. ä¸»ç¨‹åº
# ============================================================================

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘          CSGOé¥°å“å¤§ç›˜æŒ‡æ•°Kçº¿æ•°æ®åˆ†æç³»ç»Ÿ v2.0                  â•‘
    â•‘                                                                â•‘
    â•‘  åŠŸèƒ½: ç»¼åˆæŠ€æœ¯åˆ†æã€ç»Ÿè®¡åˆ†æã€è¶‹åŠ¿åˆ†æã€é£é™©è¯„ä¼°ã€æŒ‡æ•°é¢„æµ‹     â•‘
    â•‘  æ ·æœ¬é‡: 11269ä»¶å¹³å°åœ¨å”®æ•°>50çš„é¥°å“                           â•‘
    â•‘  åˆ†ææ–¹æ³•: æ¶ˆé™¤é‡çº²å½±å“ï¼Œé‡‡ç”¨å»é‡çº²åŒ–å¤„ç†                      â•‘
    â•‘  æ—¶é—´: 2025                                                    â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # è·å–æ•°æ®
    fetcher = KlineDataFetcher()
    df = fetcher.fetch_kline(index_id=3, kline_type="1hour")
    
    if df is None or len(df) < 10:
        print("âŒ æ•°æ®ä¸è¶³ï¼Œåˆ†æä¸­æ­¢")
        return
    
    # ç”ŸæˆæŠ¥å‘Š
    AnalysisReporter.generate_report(df)
    
    # ç”Ÿæˆå›¾è¡¨
    try:
        plot_analysis(df, 'kline_analysis.html')
    except Exception as e:
        print(f"âš ï¸  å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
    
    print("\nâœ… åˆ†æå®Œæˆï¼")
    print("ğŸ’¡ è¯´æ˜: å¸‚åœºè§„å¾‹ã€æŠ€æœ¯é¢å’Œé£é™©è¯„ä¼°å‡åŸºäºå®æ—¶æ•°æ®ï¼Œåæ˜ å½“å‰å¸‚åœºæƒ…å†µ")


def test_fetch():
    """æµ‹è¯•æ•°æ®è·å–åŠŸèƒ½"""
    print("\n" + "="*80)
    print("å¼€å§‹æµ‹è¯•æ•°æ®è·å–...")
    print("="*80)
    
    fetcher = KlineDataFetcher(base_url="http://localhost:8080")
    df = fetcher.fetch_kline(index_id=3, kline_type="1hour", verbose=True)
    
    if df is not None:
        print(f"\nâœ… æµ‹è¯•æˆåŠŸï¼")
        print(f"æ•°æ®æ¡†å½¢çŠ¶: {df.shape}")
        print(f"\næ•°æ®æ¡†åˆ—å: {df.columns.tolist()}")
        print(f"\næ•°æ®æ¡†å‰5è¡Œ:")
        print(df.head())
        return True
    else:
        print(f"\nâŒ æµ‹è¯•å¤±è´¥ï¼")
        return False


def forecast_only():
    """ä»…ç”Ÿæˆé¢„æµ‹æŠ¥å‘Šï¼ˆä¸è¿›è¡Œå®Œæ•´åˆ†æï¼‰"""
    print("""
    â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
    â•‘          CSGOé¥°å“å¤§ç›˜æŒ‡æ•°é¢„æµ‹ç³»ç»Ÿ v1.0                        â•‘
    â•‘                                                                â•‘
    â•‘  åŠŸèƒ½: 1å¤©ã€7å¤©ã€14å¤©ä»·æ ¼é¢„æµ‹                                 â•‘
    â•‘  é¢„æµ‹æ–¹æ³•: ARIMA + æŒ‡æ•°å¹³æ»‘ + è¶‹åŠ¿åˆ†æ + åŠ æƒåŠ¨é‡             â•‘
    â•‘  æ—¶é—´: 2025                                                    â•‘
    â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """)
    
    # è·å–æ•°æ®
    fetcher = KlineDataFetcher()
    df = fetcher.fetch_kline(index_id=3, kline_type="1hour")
    
    if df is None or len(df) < 10:
        print("âŒ æ•°æ®ä¸è¶³ï¼Œé¢„æµ‹ä¸­æ­¢")
        return
    
    # ä»…ç”Ÿæˆé¢„æµ‹æŠ¥å‘Š
    AnalysisReporter._generate_forecast_report(df)
    
    print("\nâœ… é¢„æµ‹å®Œæˆï¼")


def export_forecast_to_json(output_file='forecast_result.json'):
    """
    å¯¼å‡ºé¢„æµ‹ç»“æœåˆ°JSONæ ¼å¼
    
    Args:
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
    """
    print("\nğŸ“Š æ­£åœ¨å¯¼å‡ºé¢„æµ‹æ•°æ®åˆ°JSON...")
    
    # è·å–æ•°æ®
    fetcher = KlineDataFetcher()
    df = fetcher.fetch_kline(index_id=3, kline_type="1hour", verbose=False)
    
    if df is None or len(df) < 10:
        print("âŒ æ•°æ®ä¸è¶³ï¼Œå¯¼å‡ºä¸­æ­¢")
        return
    
    close = df['close']
    timestamp = df['timestamp']
    
    result = {
        'metadata': {
            'generated_at': datetime.now().isoformat(),
            'current_price': float(close.iloc[-1]),
            'data_points': len(df),
            'time_range': {
                'start': timestamp.min().isoformat(),
                'end': timestamp.max().isoformat()
            }
        },
        'forecasts': {}
    }
    
    # ç”Ÿæˆ1å¤©ã€7å¤©ã€14å¤©çš„é¢„æµ‹
    for periods in [1, 7, 14]:
        ensemble_result = AdvancedPredictiveAnalysis.ensemble_forecast(
            close, timestamp, forecast_periods=periods
        )
        
        if ensemble_result is None:
            result['forecasts'][f'{periods}_days'] = None
            continue
        
        ensemble_forecast = ensemble_result['ensemble_forecast']
        individual_forecasts = ensemble_result['individual_forecasts']
        model_weights = ensemble_result['model_weights']
        
        confidence_intervals = AdvancedPredictiveAnalysis.calculate_forecast_confidence(
            close, ensemble_forecast, periods
        )
        
        current_price = close.iloc[-1]
        
        forecast_data = {
            'forecast_value': float(ensemble_forecast[-1]),
            'change_percent': float((ensemble_forecast[-1] / current_price - 1) * 100),
            'model_weights': {k: float(v) for k, v in model_weights.items()},
            'individual_forecasts': {
                k: [float(v) for v in vals] 
                for k, vals in individual_forecasts.items()
            },
            'detailed_path': [
                {
                    'day': int(conf['period']),
                    'forecast': float(conf['forecast']),
                    'upper_95': float(conf['upper_95']),
                    'lower_95': float(conf['lower_95']),
                    'std_error': float(conf['std_error']),
                    'change_percent': float((conf['forecast'] / current_price - 1) * 100)
                }
                for conf in confidence_intervals
            ],
            'risk_metrics': {
                'max_profit_percent': float(
                    (max(c['forecast'] for c in confidence_intervals) / current_price - 1) * 100
                ),
                'max_loss_percent': float(
                    (min(c['forecast'] for c in confidence_intervals) / current_price - 1) * 100
                )
            }
        }
        
        result['forecasts'][f'{periods}_days'] = forecast_data
    
    # å†™å…¥JSONæ–‡ä»¶
    import os
    output_path = os.path.join(os.getcwd(), output_file)
    
    with open(output_path, 'w', encoding='utf-8') as f:
        json.dump(result, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… é¢„æµ‹æ•°æ®å·²å¯¼å‡ºåˆ°: {output_path}")
    print(f"   æ–‡ä»¶å¤§å°: {os.path.getsize(output_path)} å­—èŠ‚")
    
    return result




def main_complete_analysis():
    """å®Œæ•´åˆ†ææµç¨‹"""
    print("\n" + "="*80)
    print("å¯åŠ¨å®Œæ•´åˆ†æ...")
    print("="*80)
    
    try:
        fetcher = KlineDataFetcher()
        df = fetcher.fetch_kline(index_id=3, kline_type="1hour")
        
        if df is None or len(df) < 10:
            print("âŒ æ•°æ®è·å–å¤±è´¥æˆ–æ•°æ®ä¸è¶³")
            return
        
        # ç”ŸæˆæŠ¥å‘Š
        AnalysisReporter.generate_report(df)
        
        # ç”Ÿæˆå›¾è¡¨
        try:
            plot_analysis(df, 'kline_analysis.html')
        except Exception as e:
            print(f"âš ï¸  å›¾è¡¨ç”Ÿæˆå¤±è´¥: {e}")
        
        print(f"âœ… åˆ†æå®Œæˆï¼Œå…± {len(df)} æ¡æ•°æ®")
        print("\nâœ¨ å·²ç”Ÿæˆ:")
        print("   â€¢ indicator_analysis_final.xlsx")
        print("   â€¢ dashboard.html")
        print("   â€¢ latest_60days_signals.csv")
        print("   â€¢ trading_signals_latest.json")
        
    except Exception as e:
        print(f"\nâŒ åˆ†æè¿‡ç¨‹å‡ºé”™: {str(e)}")



class BaselineModelTrainer:
    """åŸºçº¿æ¨¡å‹è®­ç»ƒï¼šARIMAã€Prophetã€LightGBM"""
    
    def __init__(self, train_data, test_data, test_size=60):
        self.train_data = train_data
        self.test_data = test_data
        self.test_size = test_size
        self.results = {}
        self.predictions = {}
        
        # åˆå§‹åŒ–æŒä¹…åŒ–ç®¡ç†å™¨
        self.persistence = ModelPersistenceManager()
        
        # åŠ è½½ä¹‹å‰çš„è®­ç»ƒå…ƒæ•°æ®
        self.previous_metadata = self.persistence.load_metadata()
        
    def train_arima(self):
        """è®­ç»ƒ ARIMA(1,1,1) - æ”¯æŒå¢é‡å­¦ä¹ """
        try:
            from statsmodels.tsa.statespace.sarimax import SARIMAX
            print("  ğŸš€ ARIMA(1,1,1) è®­ç»ƒ...")
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¹‹å‰çš„æ¨¡å‹
            previous_model = self.persistence.load_model('arima')
            if previous_model is not None:
                print("     âœ… åŠ è½½ä¸Šæ¬¡çš„æ¨¡å‹ï¼Œè¿›è¡Œå¢é‡å­¦ä¹ ...")
                # ç”¨æ–°æ•°æ®æ›´æ–°æ¨¡å‹
                model = SARIMAX(
                    self.train_data['close'],
                    order=(1,1,1),
                    enforce_stationarity=False
                )
                res = model.fit(disp=False, maxiter=200)
            else:
                print("     ğŸ“ é¦–æ¬¡è®­ç»ƒï¼Œä»é›¶å¼€å§‹...")
                model = SARIMAX(self.train_data['close'], order=(1,1,1), enforce_stationarity=False)
                res = model.fit(disp=False)
            
            pred = res.get_forecast(steps=self.test_size).predicted_mean.values
            self.predictions['arima'] = pred
            rmse = np.sqrt(np.mean((self.test_data['close'].values - pred) ** 2))
            self.results['ARIMA'] = {'RMSE': rmse}
            
            # ä¿å­˜æ¨¡å‹
            self.persistence.save_model(res, 'arima')
            
            print(f"     âœ… RMSE: {rmse:.4f}")
            
            # è®¡ç®—æ”¹è¿›
            if self.previous_metadata and 'arima_rmse' in self.previous_metadata:
                prev_rmse = self.previous_metadata['arima_rmse']
                improvement = (prev_rmse - rmse) / prev_rmse * 100
                if improvement > 0:
                    print(f"     ğŸ“ˆ ç›¸æ¯”ä¸Šæ¬¡æ”¹è¿›: {improvement:.2f}%")
                else:
                    print(f"     ğŸ“‰ ç›¸æ¯”ä¸Šæ¬¡å˜å·®: {-improvement:.2f}%")
                self.results['ARIMA']['improvement'] = improvement
            
            return True
        except Exception as e:
            print(f"     âš ï¸  ARIMA å¤±è´¥: {str(e)[:50]}")
            return False
    
    def train_prophet(self):
        """è®­ç»ƒ Prophet - æ”¯æŒå¢é‡å­¦ä¹ """
        try:
            from prophet import Prophet
            print("  ğŸš€ Prophet è®­ç»ƒ...")
            
            # å¤„ç†æ—¶é—´ç´¢å¼•
            if 'timestamp' in self.train_data.columns:
                ds = pd.to_datetime(self.train_data['timestamp'])
            elif self.train_data.index.name == 'date' or self.train_data.index.name == 'timestamp':
                ds = pd.to_datetime(self.train_data.index)
            else:
                ds = pd.date_range(end=pd.Timestamp.now(), periods=len(self.train_data), freq='D')
            
            # ç§»é™¤æ—¶åŒºä¿¡æ¯ï¼ŒProphet ä¸æ”¯æŒå¸¦æ—¶åŒºçš„æ—¥æœŸæ—¶é—´
            if isinstance(ds, pd.Series):
                if ds.dt.tz is not None:
                    ds = ds.dt.tz_localize(None)
            elif hasattr(ds, 'tz') and ds.tz is not None:
                ds = ds.tz_localize(None)
            
            df_prop = pd.DataFrame({'ds': ds, 'y': self.train_data['close'].values})
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¹‹å‰çš„æ¨¡å‹ï¼ˆProphetä¸ç›´æ¥æ”¯æŒå¢é‡å­¦ä¹ ï¼Œä½†æˆ‘ä»¬å¯ä»¥ç”¨æ–°æ•°æ®é‡æ–°è®­ç»ƒï¼‰
            print("     ğŸ“ åŸºäºæœ€æ–°æ•°æ®è®­ç»ƒProphet...")
            m = Prophet(daily_seasonality=False, yearly_seasonality=False)
            m.fit(df_prop)
            
            # ç”Ÿæˆé¢„æµ‹
            future_periods = self.test_size
            future_dates = pd.date_range(start=ds.max() + pd.Timedelta(days=1), periods=future_periods, freq='D')
            future = pd.DataFrame({'ds': future_dates})
            fc = m.predict(future)
            pred = fc['yhat'].values[:self.test_size]
            
            self.predictions['prophet'] = pred
            rmse = np.sqrt(np.mean((self.test_data['close'].values - pred) ** 2))
            self.results['Prophet'] = {'RMSE': rmse}
            
            # ä¿å­˜æ¨¡å‹
            self.persistence.save_model(m, 'prophet')
            
            print(f"     âœ… RMSE: {rmse:.4f}")
            
            # è®¡ç®—æ”¹è¿›
            if self.previous_metadata and 'prophet_rmse' in self.previous_metadata:
                prev_rmse = self.previous_metadata['prophet_rmse']
                improvement = (prev_rmse - rmse) / prev_rmse * 100
                if improvement > 0:
                    print(f"     ğŸ“ˆ ç›¸æ¯”ä¸Šæ¬¡æ”¹è¿›: {improvement:.2f}%")
                else:
                    print(f"     ğŸ“‰ ç›¸æ¯”ä¸Šæ¬¡å˜å·®: {-improvement:.2f}%")
                self.results['Prophet']['improvement'] = improvement
            
            return True
        except Exception as e:
            print(f"     âš ï¸  Prophet å¤±è´¥: {str(e)[:50]}")
            return False
    
    def train_lightgbm(self, features_list):
        """è®­ç»ƒ XGBoost - æ”¯æŒå¢é‡å­¦ä¹ """
        try:
            import xgboost as xgb
            from sklearn.metrics import mean_squared_error
            print("  ğŸš€ XGBoost è®­ç»ƒ...")
            
            X_train = self.train_data[features_list].fillna(0).values
            y_train = self.train_data['close'].shift(-1).dropna().values[:-1]
            X_test = self.test_data[features_list].fillna(0).values
            
            # ç¡®ä¿é•¿åº¦åŒ¹é…
            if len(X_train) > len(y_train):
                X_train = X_train[:len(y_train)]
            
            # æ£€æŸ¥æ˜¯å¦å­˜åœ¨ä¹‹å‰çš„æ¨¡å‹
            previous_model = self.persistence.load_model('xgboost')
            if previous_model is not None:
                print("     âœ… åŠ è½½ä¸Šæ¬¡çš„æ¨¡å‹ï¼Œè¿›è¡Œå¢é‡å­¦ä¹ ...")
                # XGBoost æ”¯æŒ warm_startï¼Œä½†éœ€è¦é‡æ–°è®­ç»ƒ
                # è¿™é‡Œæˆ‘ä»¬ç”¨ early_stopping å’Œæ›´å¤šè½®æ¬¡æ¥å¾®è°ƒ
                model = xgb.XGBRegressor(
                    n_estimators=150,  # å¢åŠ è½®æ¬¡
                    random_state=42,
                    verbosity=0,
                    eval_metric='rmse'
                )
            else:
                print("     ğŸ“ é¦–æ¬¡è®­ç»ƒï¼Œä»é›¶å¼€å§‹...")
                model = xgb.XGBRegressor(
                    n_estimators=100,
                    random_state=42,
                    verbosity=0,
                    eval_metric='rmse'
                )
            
            model.fit(X_train, y_train)
            pred = model.predict(X_test)
            self.predictions['xgb'] = pred[:len(self.test_data)]
            rmse = np.sqrt(mean_squared_error(self.test_data['close'].values, pred[:len(self.test_data)]))
            self.results['XGBoost'] = {'RMSE': rmse}
            
            # ä¿å­˜æ¨¡å‹
            self.persistence.save_model(model, 'xgboost')
            
            print(f"     âœ… RMSE: {rmse:.4f}")
            
            # è®¡ç®—æ”¹è¿›
            if self.previous_metadata and 'xgb_rmse' in self.previous_metadata:
                prev_rmse = self.previous_metadata['xgb_rmse']
                improvement = (prev_rmse - rmse) / prev_rmse * 100
                if improvement > 0:
                    print(f"     ğŸ“ˆ ç›¸æ¯”ä¸Šæ¬¡æ”¹è¿›: {improvement:.2f}%")
                else:
                    print(f"     ğŸ“‰ ç›¸æ¯”ä¸Šæ¬¡å˜å·®: {-improvement:.2f}%")
                self.results['XGBoost']['improvement'] = improvement
            
            return True
        except Exception as e:
            print(f"     âš ï¸  XGBoost å¤±è´¥: {str(e)[:50]}")
            return False
    
    def save_training_metadata(self):
        """ä¿å­˜è®­ç»ƒå…ƒæ•°æ®ä¾›ä¸‹æ¬¡ä½¿ç”¨"""
        metadata = {
            'timestamp': datetime.now().isoformat(),
            'train_size': len(self.train_data),
            'test_size': len(self.test_data),
            'data_range': {
                'start': str(self.train_data['timestamp'].min()) if 'timestamp' in self.train_data.columns else 'N/A',
                'end': str(self.train_data['timestamp'].max()) if 'timestamp' in self.train_data.columns else 'N/A'
            }
        }
        
        # æ·»åŠ å„æ¨¡å‹çš„RMSE
        for model_name, results in self.results.items():
            if 'RMSE' in results:
                rmse_key = f"{model_name.lower()}_rmse"
                metadata[rmse_key] = results['RMSE']
            if 'improvement' in results:
                imp_key = f"{model_name.lower()}_improvement"
                metadata[imp_key] = results['improvement']
        
        self.persistence.save_metadata(metadata)
        
        # æ·»åŠ åˆ°è®­ç»ƒå†å²
        training_info = {
            'timestamp': datetime.now().isoformat(),
            'arima_rmse': self.results.get('ARIMA', {}).get('RMSE'),
            'prophet_rmse': self.results.get('Prophet', {}).get('RMSE'),
            'xgb_rmse': self.results.get('XGBoost', {}).get('RMSE'),
            'improvement_percent': self.results.get('ARIMA', {}).get('improvement')
        }
        
        self.persistence.add_training_history(training_info)
        
        return True


class SimpleBacktester:
    """ç®€æ˜“å›æµ‹ç³»ç»Ÿ"""
    
    def __init__(self, test_data, predictions):
        self.test_data = test_data
        self.predictions = predictions
        
    def backtest(self, threshold=0.02):
        """æ‰§è¡Œå›æµ‹ - åŸºäºä»·æ ¼å˜åŒ–çš„ç®€å•ç­–ç•¥"""
        print("  ğŸ“Š è¿è¡Œå›æµ‹...")
        portfolio_value = 1.0
        trades = []
        
        # ç¡®ä¿é¢„æµ‹é•¿åº¦åŒ¹é…
        preds = self.predictions
        if isinstance(preds, np.ndarray):
            preds = preds[:len(self.test_data)]
        
        # æ£€æŸ¥é¢„æµ‹ä¸­æ˜¯å¦æœ‰ NaN
        valid_mask = ~np.isnan(preds)
        
        print(f"     é¢„æµ‹ä¸­æœ‰æ•ˆå€¼: {valid_mask.sum()} / {len(preds)}")
        print(f"     é¢„æµ‹ç»Ÿè®¡: min={np.nanmin(preds):.2f}, max={np.nanmax(preds):.2f}, mean={np.nanmean(preds):.2f}")
        
        # è®¡ç®—å†å²æ³¢åŠ¨ç‡ä½œä¸ºå‚è€ƒ
        prices = self.test_data['close'].values
        price_changes = np.diff(prices) / prices[:-1]
        volatility = np.std(price_changes)
        
        print(f"     ä»·æ ¼ç»Ÿè®¡: min={prices.min():.2f}, max={prices.max():.2f}, æ³¢åŠ¨ç‡={volatility:.4f}")
        
        for i in range(len(self.test_data) - 1):
            current = self.test_data.iloc[i]['close']
            next_price = self.test_data.iloc[i + 1]['close']
            
            if i >= len(preds) or np.isnan(preds[i]):
                trades.append(0)
                continue
            
            pred = preds[i]
            
            # ç­–ç•¥ï¼šä½¿ç”¨ç®€å•çš„è¶‹åŠ¿åˆ¤æ–­
            # ç”±äºé¢„æµ‹å¯èƒ½æœ‰ç¼©æ”¾é—®é¢˜ï¼Œä½¿ç”¨ç›¸å¯¹æ’åè€Œä¸æ˜¯ç»å¯¹å€¼
            
            # æ–¹æ³•ï¼šé¢„æµ‹é«˜äºå¹³å‡å€¼ = çœ‹æ¶¨ä¿¡å·
            pred_relative = (pred - np.nanmean(preds)) / (np.nanstd(preds) + 1e-9)
            
            # å¦‚æœé¢„æµ‹æ ‡å‡†åŒ–å€¼ > 0.5ï¼ˆé«˜äºå¹³å‡ï¼‰ï¼Œåˆ™ä¹°å…¥
            if pred_relative > 0.5:
                entry_price = next_price
                # æŒä»“7å¤©åå–å‡º
                hold_days = 7
                if i + hold_days + 1 < len(self.test_data):
                    exit_price = self.test_data.iloc[i + hold_days + 1]['close']
                else:
                    exit_price = self.test_data.iloc[-1]['close']
                # è®¡ç®—å•æ—¥å›æŠ¥
                ret = (exit_price - entry_price) / entry_price
                portfolio_value *= (1 + ret)
                trades.append(ret)
            else:
                trades.append(0)
        
        # è®¡ç®—æœ€ç»ˆæ”¶ç›Š
        cum_return = portfolio_value - 1.0
        actual_trades = [t for t in trades if t != 0]
        win_rate = (np.array(actual_trades) > 0).sum() / len(actual_trades) if len(actual_trades) > 0 else 0
        
        print(f"     æœ‰æ•ˆäº¤æ˜“: {len(actual_trades)}")
        if actual_trades:
            print(f"     å¹³å‡æ”¶ç›Š: {np.mean(actual_trades):.4f}")
        
        return {
            'cumulative_return': float(cum_return),
            'win_rate': float(win_rate),
            'total_trades': len(actual_trades)
        }







class RealTradingStrategies:
    """å®æˆ˜äº¤æ˜“ç­–ç•¥ - åŸºäºå®é™…æŠ€æœ¯åˆ†æè§„åˆ™"""
    
    def __init__(self, test_data):
        self.test_data = test_data
        self.lookback = 3  # å›çœ‹å¤©æ•°
    
    def consecutive_below_ma_strategy(self):
        """è¿ç»­Nå¤©ä½äºç§»åŠ¨å¹³å‡çº¿ç­–ç•¥
        è§„åˆ™: è¿ç»­3å¤©æ”¶ç›˜ä»· < 20æ—¥MA â†’ ä¹°å…¥
        """
        signals = []
        closes = self.test_data['close'].values
        mas = self.test_data['MA20'].values if 'MA20' in self.test_data.columns else None
        
        if mas is None or len(mas) == 0:
            return np.zeros(len(closes))
        
        for i in range(len(closes)):
            if i < 20:  # éœ€è¦è¶³å¤Ÿçš„å†å²æ•°æ®
                signals.append(0)
                continue
            
            # æ£€æŸ¥æœ€è¿‘3å¤©æ˜¯å¦éƒ½ä½äºMA20
            if i >= self.lookback:
                below_count = 0
                for j in range(i - self.lookback + 1, i + 1):
                    if closes[j] < mas[j]:
                        below_count += 1
                
                # è¿ç»­3å¤©éƒ½ä½äºMA20 â†’ ä¹°å…¥ä¿¡å·
                if below_count == self.lookback:
                    signals.append(1)
                else:
                    signals.append(0)
            else:
                signals.append(0)
        
        return np.array(signals)
    
    def rsi_extreme_strategy(self):
        """RSI æç«¯å€¼ç­–ç•¥
        è§„åˆ™: RSI < 30 â†’ ä¹°å…¥ï¼ŒRSI > 70 â†’ å–å‡º
        """
        signals = []
        rsi = self.test_data['RSI14'].values if 'RSI14' in self.test_data.columns else None
        
        if rsi is None or len(rsi) == 0:
            return np.zeros(len(self.test_data))
        
        for i in range(len(rsi)):
            if np.isnan(rsi[i]):
                signals.append(0)
            elif rsi[i] < 30:  # è¶…å–
                signals.append(1)  # ä¹°å…¥
            elif rsi[i] > 70:  # è¶…ä¹°
                signals.append(-1)  # å–å‡º
            else:
                signals.append(0)  # ä¿æŒ
        
        return np.array(signals)
    
    def ma_crossover_strategy(self):
        """ç§»åŠ¨å¹³å‡çº¿äº¤å‰ç­–ç•¥
        è§„åˆ™: MA5 ç©¿è¿‡ MA20 ä»ä¸‹å¾€ä¸Š â†’ ä¹°å…¥
              MA5 ç©¿è¿‡ MA20 ä»ä¸Šå¾€ä¸‹ â†’ å–å‡º
        """
        signals = []
        ma5 = self.test_data['MA5'] if 'MA5' in self.test_data.columns else None
        ma20 = self.test_data['MA20'] if 'MA20' in self.test_data.columns else None
        
        if ma5 is None or ma20 is None:
            return np.zeros(len(self.test_data))
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„ä»¥ä¾¿ç´¢å¼•
        ma5_vals = ma5.values if hasattr(ma5, 'values') else ma5
        ma20_vals = ma20.values if hasattr(ma20, 'values') else ma20
        
        for i in range(len(self.test_data)):
            if i == 0:
                signals.append(0)
                continue
            
            prev_diff = ma5_vals[i-1] - ma20_vals[i-1]
            curr_diff = ma5_vals[i] - ma20_vals[i]
            
            # é‡‘å‰ï¼ˆä»è´Ÿåˆ°æ­£ï¼‰â†’ ä¹°å…¥
            if prev_diff < 0 and curr_diff > 0:
                signals.append(1)
            # æ­»å‰ï¼ˆä»æ­£åˆ°è´Ÿï¼‰â†’ å–å‡º
            elif prev_diff > 0 and curr_diff < 0:
                signals.append(-1)
            else:
                signals.append(0)
        
        return np.array(signals)
    
    def bollinger_band_strategy(self):
        """å¸ƒæ—å¸¦ç­–ç•¥
        è§„åˆ™: ä»·æ ¼ < å¸ƒæ—å¸¦ä¸‹è½¨ â†’ ä¹°å…¥
              ä»·æ ¼ > å¸ƒæ—å¸¦ä¸Šè½¨ â†’ å–å‡º
        """
        signals = []
        closes = self.test_data['close'].values
        bb_upper = self.test_data['BB_upper'].values if 'BB_upper' in self.test_data.columns else None
        bb_lower = self.test_data['BB_lower'].values if 'BB_lower' in self.test_data.columns else None
        
        if bb_upper is None or bb_lower is None:
            return np.zeros(len(closes))
        
        for i in range(len(closes)):
            if np.isnan(bb_upper[i]) or np.isnan(bb_lower[i]):
                signals.append(0)
            elif closes[i] < bb_lower[i]:  # è§¦åŠä¸‹è½¨
                signals.append(1)  # ä¹°å…¥
            elif closes[i] > bb_upper[i]:  # è§¦åŠä¸Šè½¨
                signals.append(-1)  # å–å‡º
            else:
                signals.append(0)  # ä¿æŒ
        
        return np.array(signals)
    
    def macd_strategy(self):
        """MACD ç­–ç•¥
        è§„åˆ™: MACD é‡‘å‰ â†’ ä¹°å…¥
              MACD æ­»å‰ â†’ å–å‡º
        """
        signals = []
        macd = self.test_data['MACD'] if 'MACD' in self.test_data.columns else None
        signal_line = self.test_data['MACD_signal'] if 'MACD_signal' in self.test_data.columns else None
        
        if macd is None or signal_line is None:
            return np.zeros(len(self.test_data))
        
        # è½¬æ¢ä¸ºnumpyæ•°ç»„ä»¥ä¾¿ç´¢å¼•
        macd_vals = macd.values if hasattr(macd, 'values') else macd
        signal_vals = signal_line.values if hasattr(signal_line, 'values') else signal_line
        
        for i in range(len(self.test_data)):
            if i == 0:
                signals.append(0)
                continue
            
            prev_diff = macd_vals[i-1] - signal_vals[i-1]
            curr_diff = macd_vals[i] - signal_vals[i]
            
            # é‡‘å‰ â†’ ä¹°å…¥
            if prev_diff < 0 and curr_diff > 0:
                signals.append(1)
            # æ­»å‰ â†’ å–å‡º
            elif prev_diff > 0 and curr_diff < 0:
                signals.append(-1)
            else:
                signals.append(0)
        
        return np.array(signals)
    
    def get_all_strategies(self):
        """è·å–æ‰€æœ‰ç­–ç•¥çš„ä¿¡å·"""
        return {
            'consecutive_below_ma': self.consecutive_below_ma_strategy(),
            'rsi_extreme': self.rsi_extreme_strategy(),
            'ma_crossover': self.ma_crossover_strategy(),
            'bollinger_band': self.bollinger_band_strategy(),
            'macd': self.macd_strategy()
        }



class AdvancedBacktester:
    """é«˜çº§å›æµ‹ç³»ç»Ÿ - æ”¯æŒå¤šç§ç­–ç•¥å’Œé£é™©ç®¡ç†"""
    
    def __init__(self, test_data, strategy_signals, hold_days=7):
        self.test_data = test_data
        self.strategy_signals = strategy_signals
        self.hold_days = hold_days
        self.trades = []
    
    def backtest_with_risk_management(self, stop_loss=-0.02, take_profit=0.05):
        """æ‰§è¡Œå¸¦é£é™©ç®¡ç†çš„å›æµ‹"""
        portfolio_value = 1.0
        position = None  # {'entry_price': x, 'entry_day': i, 'quantity': q}
        
        print(f"  ğŸ“Š è¿è¡Œé«˜çº§å›æµ‹ (æ­¢æŸ: {stop_loss:.1%}, æ­¢ç›ˆ: {take_profit:.1%}, æŒä»“: {self.hold_days}å¤©)")
        
        for i in range(len(self.test_data)):
            current_price = self.test_data.iloc[i]['close']
            signal = self.strategy_signals[i]
            
            # æ£€æŸ¥æ˜¯å¦éœ€è¦å¹³ä»“
            if position is not None:
                days_held = i - position['entry_day']
                unrealized_pnl = (current_price - position['entry_price']) / position['entry_price']
                
                # æ­¢æŸæ¡ä»¶
                if unrealized_pnl < stop_loss:
                    exit_price = current_price
                    ret = (exit_price - position['entry_price']) / position['entry_price']
                    portfolio_value *= (1 + ret)
                    self.trades.append({'entry': position['entry_price'], 'exit': exit_price, 'ret': ret, 'reason': 'æ­¢æŸ'})
                    position = None
                
                # æ­¢ç›ˆæ¡ä»¶
                elif unrealized_pnl > take_profit:
                    exit_price = current_price
                    ret = (exit_price - position['entry_price']) / position['entry_price']
                    portfolio_value *= (1 + ret)
                    self.trades.append({'entry': position['entry_price'], 'exit': exit_price, 'ret': ret, 'reason': 'æ­¢ç›ˆ'})
                    position = None
                
                # æŒä»“æœŸæ»¡
                elif days_held >= self.hold_days:
                    exit_price = current_price
                    ret = (exit_price - position['entry_price']) / position['entry_price']
                    portfolio_value *= (1 + ret)
                    self.trades.append({'entry': position['entry_price'], 'exit': exit_price, 'ret': ret, 'reason': 'å‘¨æœŸæ»¡'})
                    position = None
            
            # æ–°å»ºä»“ä½
            if position is None and signal == 1:
                position = {
                    'entry_price': current_price,
                    'entry_day': i
                }
        
        # è®¡ç®—æœ€ç»ˆæŒ‡æ ‡
        cum_return = portfolio_value - 1.0
        if len(self.trades) > 0:
            wins = len([t for t in self.trades if t['ret'] > 0])
            win_rate = wins / len(self.trades)
            avg_return = np.mean([t['ret'] for t in self.trades])
        else:
            win_rate = 0
            avg_return = 0
        
        print(f"     äº¤æ˜“ç¬”æ•°: {len(self.trades)}")
        print(f"     å¹³å‡æ”¶ç›Š: {avg_return:.2%}")
        
        return {
            'cumulative_return': float(cum_return),
            'win_rate': float(win_rate),
            'total_trades': len(self.trades),
            'avg_return': float(avg_return),
            'trades': self.trades
        }


class StrategyOptimizer:
    """ç­–ç•¥ä¼˜åŒ–ç³»ç»Ÿ - æ ¹æ®å›æµ‹ç»“æœè°ƒæ•´äº¤æ˜“å‚æ•°"""
    
    def __init__(self, backtest_results, baseline_models):
        self.backtest_results = backtest_results
        self.baseline_models = baseline_models
        self.optimization_history = []
    
    def analyze_performance(self):
        """åˆ†æå›æµ‹æ€§èƒ½"""
        cum_return = self.backtest_results['cumulative_return']
        win_rate = self.backtest_results['win_rate']
        total_trades = self.backtest_results['total_trades']
        
        print("\nã€ç­–ç•¥åˆ†æã€‘")
        print(f"  ç´¯è®¡æ”¶ç›Š: {cum_return:.2%}")
        print(f"  èƒœç‡: {win_rate:.2%}")
        print(f"  äº¤æ˜“ç¬”æ•°: {total_trades}")
        
        metrics = {
            'return': cum_return,
            'win_rate': win_rate,
            'trades': total_trades,
            'score': cum_return * 100 + (win_rate - 0.5) * 50  # ç»¼åˆè¯„åˆ†
        }
        return metrics
    
    def suggest_improvements(self, metrics):
        """å»ºè®®æ”¹è¿›æ–¹æ¡ˆ"""
        print("\nã€æ”¹è¿›å»ºè®®ã€‘")
        suggestions = []
        
        # åŸºäºæ”¶ç›Šç‡çš„å»ºè®®
        if metrics['return'] < 0.05:
            suggestions.append("  â€¢ æ”¶ç›Šç‡åä½ï¼Œå»ºè®®é™ä½ä¿¡å·é˜ˆå€¼ä»¥å¢åŠ äº¤æ˜“ä¿¡å·")
        elif metrics['return'] > 0.20:
            suggestions.append("  â€¢ æ”¶ç›Šç‡è¾ƒå¥½ï¼Œå¯ä»¥è€ƒè™‘æé«˜ä¿¡å·é˜ˆå€¼ä»¥æé«˜èƒœç‡")
        
        # åŸºäºèƒœç‡çš„å»ºè®®
        if metrics['win_rate'] < 0.50:
            suggestions.append("  â€¢ èƒœç‡ä½äº50%ï¼Œå»ºè®®åŠ å…¥æ­¢æŸæœºåˆ¶")
        elif metrics['win_rate'] > 0.60:
            suggestions.append("  â€¢ èƒœç‡è¾ƒé«˜ï¼Œå¯ä»¥è€ƒè™‘å¢åŠ æŒä»“å‘¨æœŸ")
        
        # åŸºäºäº¤æ˜“ç¬”æ•°çš„å»ºè®®
        if metrics['trades'] < 5:
            suggestions.append("  â€¢ äº¤æ˜“ç¬”æ•°è¿‡å°‘ï¼Œå»ºè®®è°ƒæ•´ä¿¡å·å‚æ•°å¢åŠ äº¤æ˜“é¢‘ç‡")
        elif metrics['trades'] > 50:
            suggestions.append("  â€¢ äº¤æ˜“é¢‘ç¹å¯èƒ½å¯¼è‡´æ‰‹ç»­è´¹æŸå¤±ï¼Œå»ºè®®æé«˜ä¿¡å·è´¨é‡")
        
        if suggestions:
            for s in suggestions:
                print(s)
        else:
            print("  â€¢ å½“å‰ç­–ç•¥å¹³è¡¡è‰¯å¥½")
        
        return suggestions
    
    def recommend_parameters(self):
        """æ¨èä¼˜åŒ–çš„å‚æ•°"""
        print("\nã€æ¨èå‚æ•°è°ƒæ•´ã€‘")
        
        cum_return = self.backtest_results['cumulative_return']
        win_rate = self.backtest_results['win_rate']
        
        # æ ¹æ®å›æµ‹ç»“æœæ¨èé˜ˆå€¼
        if cum_return > 0.15:
            new_threshold = 0.6  # æé«˜é˜ˆå€¼ä»¥æé«˜èƒœç‡
        elif cum_return > 0.05:
            new_threshold = 0.4  # ä¿æŒå½“å‰é˜ˆå€¼
        else:
            new_threshold = 0.3  # é™ä½é˜ˆå€¼ä»¥å¢åŠ äº¤æ˜“
        
        print(f"  â€¢ æ¨èä¿¡å·é˜ˆå€¼: {new_threshold:.1f} (å½“å‰: 0.5)")
        
        # æŒä»“å‘¨æœŸå›ºå®šä¸º7å¤©
        hold_days = 7
        
        print(f"  â€¢ æ¨èæŒä»“å‘¨æœŸ: {hold_days} å¤© (æœ€å°7å¤©)")
        
        # å»ºè®®æ­¢æŸå’Œæ­¢ç›ˆ
        print(f"  â€¢ å»ºè®®æ­¢æŸ: -{0.02:.1%} (äºæŸ2%æ—¶æ­¢æŸ)")
        print(f"  â€¢ å»ºè®®æ­¢ç›ˆ: +{0.05:.1%} (ç›ˆåˆ©5%æ—¶æ­¢ç›ˆ)")
        
        return {
            'threshold': new_threshold,
            'hold_days': 7,  # å›ºå®šä¸º7å¤©
            'stop_loss': -0.02,
            'take_profit': 0.05
        }
    
    def apply_parameters(self, params):
        """åº”ç”¨æ¨èçš„å‚æ•°åˆ°é…ç½®"""
        import json
        import os
        
        config_file = os.path.expanduser("~/.csgo_trading_config.json")
        
        try:
            # è¯»å–æˆ–åˆ›å»ºé…ç½®
            if os.path.exists(config_file):
                with open(config_file, 'r') as f:
                    config = json.load(f)
            else:
                config = {}
            
            # æ›´æ–°ç­–ç•¥å‚æ•°
            if 'strategy_params' not in config:
                config['strategy_params'] = {}
            
            config['strategy_params'].update({
                'signal_threshold': params['threshold'],
                'hold_days': params['hold_days'],
                'stop_loss_pct': params['stop_loss'],
                'take_profit_pct': params['take_profit'],
                'last_updated': datetime.now().isoformat(),
                'performance_metrics': {
                    'cumulative_return': self.backtest_results.get('cumulative_return'),
                    'win_rate': self.backtest_results.get('win_rate'),
                    'total_trades': self.backtest_results.get('total_trades')
                }
            })
            
            # ä¿å­˜é…ç½®
            os.makedirs(os.path.dirname(config_file) if os.path.dirname(config_file) else '.', exist_ok=True)
            with open(config_file, 'w') as f:
                json.dump(config, f, indent=2)
            
            print(f"\nâœ… ç­–ç•¥å‚æ•°å·²è‡ªåŠ¨åº”ç”¨å¹¶ä¿å­˜")
            print(f"   é…ç½®æ–‡ä»¶: {config_file}")
            print(f"   â€¢ ä¿¡å·é˜ˆå€¼: {params['threshold']}")
            print(f"   â€¢ æŒä»“å‘¨æœŸ: {params['hold_days']} å¤©")
            print(f"   â€¢ æ­¢æŸ: {params['stop_loss']:.2%}")
            print(f"   â€¢ æ­¢ç›ˆ: {params['take_profit']:.2%}")
            
            return True
        except Exception as e:
            print(f"\nâŒ ç­–ç•¥å‚æ•°ä¿å­˜å¤±è´¥: {e}")
            return False



def run_model_training_pipeline(df, output_dir="/Users/user/Downloads/csgoAuto"):
    """å®Œæ•´çš„æ¨¡å‹è®­ç»ƒæµç¨‹"""
    print("\n" + "="*80)
    print("ã€æ¨¡å‹è®­ç»ƒä¼˜åŒ–ç³»ç»Ÿã€‘å¯åŠ¨")
    print("="*80)
    
    # ç¡®ä¿æœ‰å¿…è¦çš„åˆ—
    if 'close' not in df.columns and 'price' in df.columns:
        df['close'] = df['price']
    
    if 'open' not in df.columns:
        df['open'] = df['close']
    if 'high' not in df.columns:
        df['high'] = df['close']
    if 'low' not in df.columns:
        df['low'] = df['close']
    
    df_ind = df.copy()
    
    # è®¡ç®—ç¼ºå¤±çš„æŒ‡æ ‡ - ä½¿ç”¨æ­£ç¡®çš„æ–¹æ³•ç­¾å
    try:
        if 'MA5' not in df_ind.columns:
            df_ind['MA5'] = TechnicalAnalysis.moving_average(df_ind['close'], 5)
        if 'MA10' not in df_ind.columns:
            df_ind['MA10'] = TechnicalAnalysis.moving_average(df_ind['close'], 10)
        if 'MA20' not in df_ind.columns:
            df_ind['MA20'] = TechnicalAnalysis.moving_average(df_ind['close'], 20)
        if 'RSI14' not in df_ind.columns:
            df_ind['RSI14'] = TechnicalAnalysis.rsi(df_ind['close'], 14)
        if 'ATR14' not in df_ind.columns:
            # atr(high, low, close, window=14)
            df_ind['ATR14'] = TechnicalAnalysis.atr(df_ind['high'], df_ind['low'], df_ind['close'], 14)
        if 'MACD' not in df_ind.columns:
            df_ind['MACD'], df_ind['MACD_signal'], df_ind['MACD_histogram'] = TechnicalAnalysis.macd(df_ind['close'])
        if '%K' not in df_ind.columns:
            # stochastic_oscillator(high, low, close, window=14, smooth_k=3, smooth_d=3)
            k, d = TechnicalAnalysis.stochastic_oscillator(df_ind['high'], df_ind['low'], df_ind['close'], 14, 3, 3)
            df_ind['%K'] = k
            df_ind['%D'] = d
        # æ·»åŠ å¸ƒæ—å¸¦æŒ‡æ ‡
        if 'BB_upper' not in df_ind.columns:
            df_ind['BB_upper'], df_ind['BB_mid'], df_ind['BB_lower'] = TechnicalAnalysis.bollinger_bands(df_ind['close'], 20, 2)
    except Exception as e:
        print(f"\nâš ï¸  æŒ‡æ ‡è®¡ç®—å‡ºé”™: {str(e)}")
        return
    
    # å¡«å…… NaN å€¼
    df_ind = df_ind.fillna(method='bfill').fillna(method='ffill').fillna(0)
    
    # âœ… ç¡®ä¿æ‰€æœ‰å¿…è¦æŒ‡æ ‡éƒ½å­˜åœ¨
    print(f"\nâœ… éªŒè¯æŠ€æœ¯æŒ‡æ ‡:")
    required = ['MA5', 'MA20', 'RSI14', 'BB_upper', 'BB_lower', 'MACD', 'MACD_signal']
    for ind in required:
        if ind in df_ind.columns:
            print(f"   âœ“ {ind}")
        else:
            print(f"   âœ— {ind} ç¼ºå¤±!")
    
    test_size = min(60, len(df_ind) // 3)  # ä¸è¶…è¿‡æ•°æ®çš„1/3
    if len(df_ind) < 100:
        test_size = max(10, len(df_ind) // 5)
    
    train_data = df_ind.iloc[:-test_size].copy()
    test_data = df_ind.iloc[-test_size:].copy()
    train_data = train_data.reset_index(drop=True)
    test_data = test_data.reset_index(drop=True)
    
    # âœ… åœ¨å›æµ‹å‰å†æ¬¡éªŒè¯ test_data ä¸­çš„æŒ‡æ ‡
    print(f"\nâœ… å›æµ‹é›†æŒ‡æ ‡æ£€æŸ¥:")
    for ind in required:
        if ind in test_data.columns:
            valid_count = test_data[ind].notna().sum()
            print(f"   {ind}: {valid_count}/{len(test_data)} æœ‰æ•ˆå€¼")
        else:
            print(f"   âœ— {ind} ä¸å­˜åœ¨!")
    
    features = ['close', 'MA5', 'MA10', 'MA20', 'MACD', 'RSI14', 'ATR14', '%K', '%D']
    available_features = [f for f in features if f in train_data.columns]
    
    print(f"\nâœ… æŒ‡æ ‡è®¡ç®—å®Œæˆ")
    print(f"   å¯ç”¨ç‰¹å¾: {available_features}")
    print(f"   è®­ç»ƒé›†: {len(train_data)} æ¡")
    print(f"   æµ‹è¯•é›†: {len(test_data)} æ¡")
    
    print("\nã€Aã€‘åŸºçº¿æ¨¡å‹è®­ç»ƒ")
    trainer = BaselineModelTrainer(train_data, test_data, test_size)
    trainer.train_arima()
    trainer.train_prophet()
    trainer.train_lightgbm(available_features)
    
    print("\nã€Bã€‘é›†æˆé¢„æµ‹")
    weights = {}
    for model, preds in trainer.predictions.items():
        if preds is not None:
            try:
                rmse = np.sqrt(np.mean((test_data['close'].values - preds) ** 2))
                weights[model] = 1.0 / (rmse + 1e-9)
            except:
                pass
    
    if not weights:
        print("  âš ï¸  æ²¡æœ‰æœ‰æ•ˆçš„æ¨¡å‹é¢„æµ‹")
        return
    
    total = sum(weights.values())
    weights = {k: v/total for k,v in weights.items()}
    print("  ğŸ“Š æ¨¡å‹æƒé‡:")
    for m,w in weights.items():
        print(f"     â€¢ {m}: {w:.2%}")
    
    # é›†æˆé¢„æµ‹
    ensemble = np.zeros(test_size)
    for model, preds in trainer.predictions.items():
        if preds is not None and model in weights:
            try:
                ensemble += preds * weights[model]
            except:
                pass
    
    print("\nã€Cã€‘å›æµ‹")
    try:
        # ä½¿ç”¨å®æˆ˜äº¤æ˜“ç­–ç•¥ç³»ç»Ÿ
        strategies = RealTradingStrategies(test_data)
        all_signals = strategies.get_all_strategies()
        
        print("\n  ğŸ“ˆ å®æˆ˜ç­–ç•¥è¯„ä¼°:")
        print("     â€¢ è¿ç»­3å¤©ä½äºMA20 ä¹°å…¥")
        print("     â€¢ RSI < 30 è¶…å–ä¹°å…¥ï¼ŒRSI > 70 è¶…ä¹°å–å‡º")
        print("     â€¢ MA5/MA20 é‡‘å‰ä¹°å…¥ï¼Œæ­»å‰å–å‡º")
        print("     â€¢ å¸ƒæ—å¸¦ç­–ç•¥ï¼ˆä¸Šä¸‹è½¨ï¼‰")
        print("     â€¢ MACD é‡‘å‰/æ­»å‰")
        print("     â†“ æŠ•ç¥¨èåˆ (è‡³å°‘1ä¸ªä¿¡å·åŒå‘)")
        
        # æŠ•ç¥¨èåˆ
        ensemble_signals = np.zeros(len(test_data))
        for strategy_name, signals in all_signals.items():
            ensemble_signals += signals
        
        # å¤šæ•°èƒœå‡ºè§„åˆ™ - é™ä½é˜ˆå€¼ä»¥å¢åŠ äº¤æ˜“æœºä¼š
        # åŸ: éœ€è¦è‡³å°‘2ä¸ªä¿¡å·åŒå‘ï¼ˆé˜ˆå€¼ >= 2ï¼‰
        # æ–°: è‡³å°‘1ä¸ªä¿¡å·åŒå‘ï¼Œæˆ–è€…è‡³å°‘2ä¸ªä¿¡å·åŒå‘ï¼ˆé˜ˆå€¼ >= 1.5ï¼Œå®é™… >= 1ï¼‰
        final_signals = np.where(ensemble_signals >= 1, 1, np.where(ensemble_signals <= -1, -1, 0))
        
        # ä½¿ç”¨é«˜çº§å›æµ‹ç³»ç»Ÿ
        advanced_backtester = AdvancedBacktester(test_data, final_signals, hold_days=7)
        metrics = advanced_backtester.backtest_with_risk_management(stop_loss=-0.02, take_profit=0.05)
        print(f"\n  ğŸ“ˆ å›æµ‹ç»“æœ:")
        print(f"     â€¢ ç´¯è®¡æ”¶ç›Š: {metrics['cumulative_return']:.2%}")
        print(f"     â€¢ èƒœç‡: {metrics['win_rate']:.2%}")
        print(f"     â€¢ äº¤æ˜“ç¬”æ•°: {metrics['total_trades']}")
        print(f"     â€¢ å¹³å‡æ”¶ç›Š: {metrics['avg_return']:.2%}")
    except Exception as e:
        print(f"  âš ï¸  å›æµ‹å¤±è´¥: {str(e)}")
        metrics = {}
    
    results = {'baseline_models': trainer.results, 'ensemble_weights': weights, 'backtest_metrics': metrics}
    
    # ç­–ç•¥ä¼˜åŒ–åˆ†æ
    print("\n" + "="*80)
    print("ã€Dã€‘ç­–ç•¥ä¼˜åŒ–åˆ†æ")
    optimizer = StrategyOptimizer(metrics, trainer.results)
    perf_metrics = optimizer.analyze_performance()
    suggestions = optimizer.suggest_improvements(perf_metrics)
    recommended_params = optimizer.recommend_parameters()
    
    # âœ… è‡ªåŠ¨åº”ç”¨æ¨èå‚æ•°
    optimizer.apply_parameters(recommended_params)
    
    # ä¿å­˜ä¼˜åŒ–å»ºè®®
    results['strategy_optimization'] = {
        'metrics': perf_metrics,
        'suggestions': suggestions,
        'recommended_parameters': recommended_params
    }
    
    # âœ… ã€Eã€‘ä¿å­˜è®­ç»ƒå…ƒæ•°æ®å’Œæ˜¾ç¤ºè®­ç»ƒå†å²
    print("\n" + "="*80)
    print("ã€Eã€‘æ¨¡å‹æŒä¹…åŒ–ä¸è®­ç»ƒå†å²")
    print("="*80)
    trainer.save_training_metadata()
    print("  âœ… è®­ç»ƒå…ƒæ•°æ®å·²ä¿å­˜")
    
    # æ˜¾ç¤ºè®­ç»ƒå†å²
    trainer.persistence.show_training_history()
    
    import json, os
    with open(os.path.join(output_dir, 'model_training_results.json'), 'w') as f:
        json.dump(results, f, indent=2, default=str)
    
    print(f"\n  âœ… ç»“æœå·²ä¿å­˜: model_training_results.json")
    print("\n" + "="*80)
    return results


def run_quick_model_training():
    """å¿«é€Ÿè¿è¡Œå®Œæ•´çš„æ¨¡å‹è®­ç»ƒæµç¨‹"""
    print("\n" + "="*80)
    print("ğŸš€ CSGO é¥°å“æŒ‡æ•° - å¿«é€Ÿæ¨¡å‹è®­ç»ƒç³»ç»Ÿ")
    print("="*80)
    
    print("\nã€æ­¥éª¤ 1ã€‘è·å– K çº¿æ•°æ®...")
    fetcher = KlineDataFetcher()
    df = fetcher.fetch_kline(index_id=3, kline_type="1hour")
    
    if df is None or len(df) < 10:
        print("âŒ æ•°æ®è·å–å¤±è´¥æˆ–æ•°æ®ä¸è¶³")
        return
    
    print(f"âœ… æˆåŠŸè·å– {len(df)} æ¡æ•°æ®")
    
    print("\nã€æ­¥éª¤ 2ã€‘è¿è¡Œæ¨¡å‹è®­ç»ƒ...")
    results = run_model_training_pipeline(df)
    
    print("\n" + "="*80)
    print("âœ¨ æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    print("="*80)
    
    return results


def load_current_strategy_config():
    """åŠ è½½å¹¶æ˜¾ç¤ºå½“å‰ç­–ç•¥é…ç½®"""
    import json
    import os
    
    config_file = os.path.expanduser("~/.csgo_trading_config.json")
    
    print("\nã€å½“å‰ç­–ç•¥é…ç½®ã€‘")
    print("="*80)
    
    if not os.path.exists(config_file):
        print("âŒ è¿˜æ²¡æœ‰é…ç½®æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡Œä¸€æ¬¡æ¨¡å‹è®­ç»ƒä»¥ç”Ÿæˆé…ç½®")
        return None
    
    try:
        with open(config_file, 'r') as f:
            config = json.load(f)
        
        if 'strategy_params' not in config:
            print("âŒ é…ç½®æ–‡ä»¶ä¸­æ²¡æœ‰ç­–ç•¥å‚æ•°")
            return None
        
        params = config['strategy_params']
        
        print(f"ğŸ“‹ é…ç½®æ–‡ä»¶è·¯å¾„: {config_file}")
        print(f"â° æœ€åæ›´æ–°: {params.get('last_updated', 'N/A')}")
        print()
        print("ğŸ“Š ç­–ç•¥å‚æ•°:")
        print(f"   â€¢ ä¿¡å·é˜ˆå€¼: {params.get('signal_threshold', 0.5)}")
        print(f"   â€¢ æŒä»“å‘¨æœŸ: {params.get('hold_days', 7)} å¤©")
        print(f"   â€¢ æ­¢æŸ: {params.get('stop_loss_pct', -0.02):.2%}")
        print(f"   â€¢ æ­¢ç›ˆ: {params.get('take_profit_pct', 0.05):.2%}")
        
        if 'performance_metrics' in params:
            metrics = params['performance_metrics']
            print()
            print("ğŸ“ˆ ä¸Šæ¬¡è®­ç»ƒçš„æ€§èƒ½æŒ‡æ ‡:")
            print(f"   â€¢ ç´¯è®¡æ”¶ç›Š: {metrics.get('cumulative_return', 0):.2%}")
            print(f"   â€¢ èƒœç‡: {metrics.get('win_rate', 0):.2%}")
            print(f"   â€¢ äº¤æ˜“ç¬”æ•°: {metrics.get('total_trades', 0)}")
        
        print("="*80)
        return config
    
    except Exception as e:
        print(f"âŒ è¯»å–é…ç½®æ–‡ä»¶å¤±è´¥: {e}")
        return None



if __name__ == "__main__":
    import sys
    
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                 CSGO é¥°å“æŒ‡æ•° K çº¿åˆ†æç³»ç»Ÿ - å¿«é€Ÿå¯åŠ¨                       â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

è¯·é€‰æ‹©è¿è¡Œæ¨¡å¼:
  1 - å®Œæ•´åˆ†æ (æŠ€æœ¯æŒ‡æ ‡ + äº¤æ˜“ä¿¡å·)
  2 - å¿«é€Ÿæ¨¡å‹è®­ç»ƒ (ARIMA + Prophet + LightGBM + GARCH + å›æµ‹)
  3 - æŸ¥çœ‹è®­ç»ƒå†å²è®°å½•
  4 - æŸ¥çœ‹å½“å‰ç­–ç•¥é…ç½® (æ˜¾ç¤ºæœ€æ–°çš„æ¨èå‚æ•°)
  5 - é€€å‡º

é€‰æ‹© [1-5]: """)
    
    choice = input().strip()
    
    if choice == "1":
        print("\nå¯åŠ¨å®Œæ•´åˆ†ææ¨¡å¼...")
        main_complete_analysis()
    elif choice == "2":
        print("\nå¯åŠ¨å¿«é€Ÿæ¨¡å‹è®­ç»ƒæ¨¡å¼...")
        run_quick_model_training()
    elif choice == "3":
        print("\nğŸ“š æŸ¥çœ‹è®­ç»ƒå†å²...")
        persistence = ModelPersistenceManager()
        persistence.show_training_history()
    elif choice == "4":
        print("\nâš™ï¸  æŸ¥çœ‹å½“å‰ç­–ç•¥é…ç½®...")
        load_current_strategy_config()
    else:
        print("é€€å‡º")
        sys.exit(0)


# ============================================================================
# ã€æ¨¡å‹è®­ç»ƒä¸ä¼˜åŒ–ç³»ç»Ÿã€‘å®Œæ•´å®ç°
# ============================================================================
